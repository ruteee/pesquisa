{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import itertools \n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mat_corrs(figsize, annot, matrix):\n",
    "    f, ax = plt.subplots(figsize=figsize)\n",
    "    cmap = sns.diverging_palette(150, 275, s=80, l=55, as_cmap=True)\n",
    "    sns.heatmap(matrix, cmap=cmap, center=0, annot=annot)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stem_corrs(x, y, figsize, labels, ang_rot_lbls):\n",
    "    x = [i for i in np.arange(0, len(y))]\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.stem(x,y, linefmt='b-', markerfmt='bo', basefmt='r-')\n",
    "    plt.xticks(x, labels, rotation='60')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig_corr(x1, x2, wlag, t_amostragem,x,y):\n",
    "    correlations = np.zeros(wlag)\n",
    "    for i in np.arange(0, wlag):\n",
    "        correlations[i] = (1/(len(x1) - i))*np.dot(x1[i:],x2[:(len(x2) - i)])\n",
    "    max_index = np.argmax(np.abs(correlations))\n",
    "    return ([max_index*t_amostragem, np.round(correlations[max_index],2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcent_diff_abs(corrs1, corrs2):\n",
    "    percent_diff = []\n",
    "    corr_vars = []\n",
    "    for  corr2, corr1 in zip(corrs2, corrs1):\n",
    "        if(corr1[3]!= 0):\n",
    "            percent_diff.append((np.abs((corr2[3] - corr1[3])/corr1[3])))\n",
    "        else:\n",
    "            percent_diff.append(np.abs(corr2[3]))\n",
    "        corr_vars.append((corr2[0], corr2[1]))\n",
    "    return [percent_diff,corr_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corrs_with_pairs( matrix, threshold = None):\n",
    "    most_correlated_var = []\n",
    "    for i in np.arange(0, len(matrix[:][:][1]), 1):\n",
    "        for j in np.arange(0, len(matrix[:][:][1]), 1):\n",
    "            if threshold == None:\n",
    "                pair_value = (i, j, matrix[i][j][0], matrix[i][j][1], matrix[i][j][3])\n",
    "                most_correlated_var.append(pair_value)\n",
    "            elif (np.abs(matrix[i][j][1]) > threshold ):\n",
    "                pair_value = (i, j, matrix[i][j][0], matrix[i][j][1], matrix[i][j][3])\n",
    "                most_correlated_var.append(pair_value)\n",
    "    return most_correlated_var   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr_var(matrix, vars):\n",
    "    correlations = []\n",
    "    for var in vars:\n",
    "        correlations.append(matrix[int(var[0])][int(var[1])][1])\n",
    "    return correlations    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dfs(dfs):\n",
    "    all_dfs = pd.concat(dfs)\n",
    "    norm_dfs = []\n",
    "   \n",
    "    all_dfs_norm =  (all_dfs - all_dfs.mean())/all_dfs.std()\n",
    "    all_dfs_norm['tout'] = all_dfs['tout']\n",
    "    \n",
    "    num_linhas = int(len(all_dfs)/len(dfs))\n",
    "    num_blocks = int(len(all_dfs)/len(dfs[0]))\n",
    "    \n",
    "    for i in np.arange(0, num_blocks):\n",
    "        df = all_dfs_norm.iloc[(i*num_linhas) : (i*num_linhas + num_linhas),:]\n",
    "        norm_dfs.append(df)\n",
    "    return norm_dfs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dfs(init, end):\n",
    "    dfs = []\n",
    "    for i in np.arange(init,end + 1):\n",
    "        dfs.append(pd.read_csv('/home/rute/Pesquisa/data_dezembro/simout_' + str(i) + '.csv'))\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_correlation(wlag, dfs = []):\n",
    "    matrix_corr_list = []\n",
    "    m_sum_complete = np.zeros([22 , 22, 4])\n",
    "    dfs_norm = normalize_dfs(dfs)\n",
    "    \n",
    "    for df in dfs_norm:\n",
    "        tam_m = int(len(df.columns[1:23]))\n",
    "        m_corr = np.zeros((tam_m,tam_m,4))\n",
    "        for i, x in enumerate(df.columns[1:23]):\n",
    "            for j, y in enumerate(df.columns[1:23]):\n",
    "                corr = sig_corr(np.array(df[x]), np.array(df[y]),wlag, 0.01, x, y)\n",
    "                corr.extend([0,0])\n",
    "                m_corr[i][j] = corr\n",
    "        matrix_corr_list.append(m_corr)\n",
    "    \n",
    "    for m in matrix_corr_list:\n",
    "        m[:,:,1] = m[:,:,1]/np.diagonal(m[:,:,1])\n",
    "\n",
    "    m_mean = np.round(np.mean(matrix_corr_list, axis =0),2)\n",
    "    m_std = np.std(matrix_corr_list, axis=0)\n",
    "\n",
    "    for i in np.arange(0, len(m_mean)):\n",
    "        for j in np.arange(0, len(m_mean)):\n",
    "            m_mean[i][j][2] = m_std[i][j][0]\n",
    "            m_mean[i][j][3] = m_std[i][j][1]\n",
    "    return m_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_sims = get_dfs(1,10)\n",
    "disturb_1_sims = get_dfs(11,14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wlag = int(2/0.01)\n",
    "corrs_reg_sims = mean_correlation(wlag, regular_sims)\n",
    "corrs_dist_1_25 = mean_correlation(wlag, [disturb_1_sims[0]])\n",
    "corrs_dist_1_50 = mean_correlation(wlag, [disturb_1_sims[1]])\n",
    "corrs_dist_1_75 = mean_correlation(wlag, [disturb_1_sims[2]])\n",
    "corrs_dist_1_100 = mean_correlation(wlag, [disturb_1_sims[3]])\n",
    "\n",
    "corrs_no_dist_with_pairs = get_corrs_with_pairs(corrs_reg_sims)\n",
    "corrs_25_with_pairs_d1 = get_corrs_with_pairs(corrs_dist_1_25)\n",
    "corrs_50_with_pairs_d1 = get_corrs_with_pairs(corrs_dist_1_50)\n",
    "corrs_75_with_pairs_d1 = get_corrs_with_pairs(corrs_dist_1_75)\n",
    "corrs_100_with_pairs_d1 = get_corrs_with_pairs(corrs_dist_1_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_percent = pcent_diff_abs(corrs_no_dist_with_pairs, corrs_25_with_pairs_d1)\n",
    "perc_serie  = pd.Series(diff_percent[0], index=diff_percent[1])\n",
    "perc_serie.sort_values(inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#disturb_1_sims[3][disturb_1_sims[3].columns[1:]].plot(figsize=(16,30), subplots=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
