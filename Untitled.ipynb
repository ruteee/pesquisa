{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in /home/rute/anaconda3/lib/python3.7/site-packages (0.10.1)\n",
      "Requirement already up-to-date: pip in /home/rute/anaconda3/lib/python3.7/site-packages (19.3.1)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"k2_alg.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1ulBNSEAycgA_ksKV15iTtMEm2epuaox8\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "\n",
    "from functools import reduce\n",
    "from decimal import Decimal\n",
    "import itertools\n",
    "\n",
    "from graphviz import Digraph\n",
    "\n",
    "import TransEntropy_mod as te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_simple(df, eng = 'dot'):\n",
    "    edge_style = \"\"\n",
    "    g = Digraph(engine=eng)\n",
    "    in_graph = []\n",
    "    for k, row in enumerate(df.index):\n",
    "        if any(df.loc[row]):\n",
    "            g.node(str(row),row, shape='oval', fontsize='10', width='0', style='filled', fillcolor='#c9c9c9', color=\"gray\")\n",
    "            in_graph.append(row)\n",
    "\n",
    "              \n",
    "    for c, col in enumerate(df.columns):\n",
    "      if any(df[col]):\n",
    "        if col not in in_graph:\n",
    "            g.node(str(col), col, shape='oval', fontsize='10', width='0', style='filled', fillcolor='#c9c9c9', color=\"gray\") \n",
    "\n",
    "    for j, col in enumerate(df.columns):\n",
    "        for i, row in enumerate(df.index):\n",
    "            if(df[col][i]):\n",
    "                g.edge(str(row), str(col), label=str(df.at[row,col]), style= edge_style, color='black')  \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_from_dict(dictionary, eng = 'dot'):\n",
    "    edge_style = \"\"\n",
    "    g = Digraph(engine=eng)\n",
    "   \n",
    "    for k in dictionary.keys():\n",
    "      if any([k in sub for sub in dictionary.values() for key in dictionary.keys()]) or dictionary[k]:\n",
    "        g.node(str(k),k, shape='oval', fontsize='10', width='0', style='filled', fillcolor='#c9c9c9', color=\"gray\") \n",
    "\n",
    "    for k, i in dictionary.items():\n",
    "        for it in i:\n",
    "            g.edge(str(it), str(k), label='',style= edge_style, color='black')  \n",
    "    return g\n",
    "\n",
    "fake_data = pd.DataFrame(columns=[\"x1\", \"x2\", \"x3\"], data= np.transpose([[1,1,0,1,0,0,1,0,1,0], [0,1,0,1,0,1,1,0,1,0], [0,1,1,1,0,1,1,0,1,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(df, i, parents): \n",
    "  parents = np.sort(parents)\n",
    "  states = list(map(list, itertools.product([0, 1], repeat=len(parents)+1)))\n",
    "  states_mod = [[\"\".join(map(str,sublist[:len(sublist)-1]))]+[str(sublist[-1])] for sublist in states]\n",
    "  gpd_values = pd.DataFrame()\n",
    "  \n",
    "  if len(parents):\n",
    "    label_parents = ''.join(parents)\n",
    "    df_to_group = pd.DataFrame(columns = [label_parents, df.columns[i]],\n",
    "                                data = np.transpose(\n",
    "                                    [df.astype(str)[parents].apply(lambda x: \"\".join(x), axis=1).values,\n",
    "                                    [str(item) for item in df[df.columns[i]]]]))\n",
    "    \n",
    "    gpd_values = df_to_group.groupby(by=\n",
    "                                     [df_to_group[label_parents],\n",
    "                                      df.columns[i]]).size()\n",
    "    \n",
    "    gpd_values = gpd_values.reset_index(name='size')\n",
    "   \n",
    "    for state in states_mod:\n",
    "      if not state in gpd_values[[label_parents, df.columns[i]]].values.tolist() :\n",
    "        gpd_values.loc[len(gpd_values)] = state+[0]\n",
    "        gpd_values.sort_values(by=[label_parents, df.columns[i]], inplace=True)\n",
    "    gpd_values.reset_index(inplace=True)\n",
    "    gpd_values = gpd_values['size']\n",
    "    \n",
    "  else:\n",
    "    gpd_values = df.groupby(df.columns[i]).size().values\n",
    "  return gpd_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_N(df, i, parents):\n",
    "  \n",
    "  parents = np.sort(parents)\n",
    "  states = list(map(list, itertools.product([0, 1], repeat=len(parents))))\n",
    "  gpd_values = None\n",
    "  N = []\n",
    "  if len(parents):\n",
    "    cols_to_group = ([index for index in parents])\n",
    "    cols_to_group.insert(0,df.columns[i])\n",
    "    N = df[cols_to_group].groupby(cols_to_group[1:]).size()\n",
    "    N = N.reset_index(name='size')\n",
    "    \n",
    "    for state in states:\n",
    "      if not state in N[cols_to_group[1:]].values.tolist() :\n",
    "        N.loc[len(N)] = state+[0]\n",
    "        N.sort_values(by=cols_to_group[1:], inplace=True)\n",
    "    N.reset_index(inplace = True)\n",
    "    N = N['size']\n",
    "  else:\n",
    "    N = df.groupby(by=df.columns[i]).size().values.sum()\n",
    "  return N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_ch(df, x_i, pi):\n",
    "  #prod = 1\n",
    "  prod = 0\n",
    "  r_i = len(df[df.columns[x_i]].unique())\n",
    "  alfa = alpha(df, x_i, pi)\n",
    "  q_i = reduce(lambda x, y: x*y, [len(pd.unique(df[pai].values)) for pai in pi]) if pi  else 0\n",
    "  Nij = get_N(df, x_i, pi)\n",
    "\n",
    "  if pi:\n",
    "    for j in np.arange(0,q_i):\n",
    "      #prod *= math.factorial(r_i - 1)/math.factorial(Nij[j] + r_i - 1)\n",
    "      prod += math.log(math.factorial(r_i - 1)) - math.log(math.factorial(Nij[j] + r_i - 1))\n",
    "      for i in np.arange(0,r_i):\n",
    "        #prod *= math.factorial(alfa[2*j + i])\n",
    "        prod += math.log(math.factorial(alfa[2*j + i]))\n",
    "  else:\n",
    "    #prod *= math.factorial(r_i - 1)/math.factorial(Nij + r_i - 1)\n",
    "    prod += math.log(math.factorial(r_i - 1)) - math.log(math.factorial(Nij + r_i - 1))\n",
    "    for i in np.arange(0, r_i):\n",
    "      prod += math.log(math.factorial(alfa[i]))\n",
    "      #prod *= math.factorial(alfa[2*j + i])\n",
    "  \n",
    "  return prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_mdl(df,x_i,pi, c):\n",
    "  N = len(df)\n",
    "  r_i = len(df[df.columns[x_i]].unique())\n",
    "  q_i = reduce(lambda x, y: x*y, [len(pd.unique(df[pai].values)) for pai in pi]) if pi  else 0\n",
    "  Nij = get_N(df, x_i, pi)\n",
    "  Nijk = alpha(df, x_i, pi)\n",
    "  pbs = 0\n",
    "  \n",
    "  if(pi):\n",
    "    for j in np.arange(0,q_i):\n",
    "      for i in np.arange(0,r_i):\n",
    "        if Nijk[2*j + i] and Nij[j]:\n",
    "          pbs += Nijk[2*j + i]*(math.log(Nijk[2*j + i]) - math.log(Nij[j]))          \n",
    "        elif Nij[j]:\n",
    "          pbs += - math.log(Nij[j])\n",
    "    pbs += -(c/2)*math.log(N)*q_i*(r_i -1)\n",
    "  else:\n",
    "    for i in np.arange(0,r_i):\n",
    "      pbs += Nijk[i]*(math.log(Nijk[i]) - math.log(Nij))\n",
    "    pbs += -(c/2)*math.log(N)*(r_i -1)\n",
    "  \n",
    "  return pbs\n",
    "\n",
    "def k2(df_general, tree_ogn, df_lags, c):\n",
    "  \"tree = copy.deepcopy(tree_ogn)\n",
    "  dict_p = {}\n",
    " \n",
    "  \n",
    "  sigma = 0\n",
    "   \n",
    "  dict_lags = te.get_all_shifts(df_lags.columns, df_lags.copy())\n",
    "  nodes = []\n",
    "  \n",
    "  dfs_list = []\n",
    "  \n",
    "  for col in df_general.columns:\n",
    "    dfs_list.append(te.gen_df_iteration(df_general, col, dict_lags))\n",
    "  \n",
    "    \n",
    "    \n",
    "  parents = [[] for node in df_general.columns]\n",
    "   \n",
    "  count = 0\n",
    "  for xi,col in enumerate(df_general.columns):\n",
    "    df = dfs_list[count]\n",
    "    count += 1\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    #pold = f_ch(df, xi, parents[xi])\n",
    "   \n",
    "    pold = f_mdl(df, xi, parents[xi], c)\n",
    "    \n",
    "    tree_xi = []\n",
    "    if tree:\n",
    "      tree_xi = tree[col]\n",
    "    \n",
    "    f_ances = []\n",
    "    while (True):\n",
    "      test_parents = [parents[xi]+[ances] for ances in tree_xi] if tree_xi else []\n",
    "\n",
    "      #f_ances = [f_ch(df, xi,parent) for parent in test_parents] if test_parents else [f_ch(df, xi, test_parents)]\n",
    "      f_ances = [f_mdl(df, xi,parent,1) for parent in test_parents] if test_parents else [f_mdl(df, xi, test_parents,c)]\n",
    "      j_max = np.argmax(f_ances)\n",
    "\n",
    "      sigma = f_ances[j_max]> pold\n",
    "        \n",
    "      if sigma:\n",
    "        parents[xi] = parents[xi] + [no for no in [tree_xi[j_max]] if no not in parents[xi]]\n",
    "        pold = f_ances[j_max]\n",
    "  \n",
    "      if tree_xi:\n",
    "        del tree_xi[j_max]\n",
    "      \n",
    "      if(not sigma) or  (not tree_xi):\n",
    "        break\n",
    "        \n",
    "  for i,parent in enumerate(parents):\n",
    "    dict_p[df_general.columns[i]] = parent\n",
    "  return dict_p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dictTree(df):\n",
    "    dict_tree = {}\n",
    "    for col in df.columns:\n",
    "        non_zero = df[col].nonzero()\n",
    "        dict_tree[col] = df[col].index[non_zero].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dictTree(df):\n",
    "    dict_tree = {}\n",
    "    for col in df.columns:\n",
    "        non_zero = df[col].nonzero()\n",
    "        dict_tree[col] = df[col].index[non_zero].values.tolist()\n",
    "    return dict_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def app_roll_mean(df, window):\n",
    "    roll  = df.copy().rolling(window).mean() \n",
    "    roll.dropna(inplace=True)\n",
    "    roll = roll.round(decimals=0).copy()\n",
    "    roll.reset_index(drop=True, inplace=True)\n",
    "    return roll\n",
    "\n",
    "\n",
    "\n",
    "dict_chest = {'present': 1, 'absent':0, 'normal': 1, 'abnormal':0, True: 1, False: 0, 'visit': 1, 'no_visit': 0, 'smoker' : 1, 'non_smoker': 0}\n",
    "chest_tree = {'Dyspnea':['Cancer', 'TbOrCa', 'Tuberculosis'], \n",
    "              'XRay':['Travel', 'Tuberculosis'], \n",
    "              'TbOrCa':['Bronchitis', 'Cancer', 'Travel'],\n",
    "             'Tuberculosis':['Travel','TbOrCa', 'Cancer'],\n",
    "             'Cancer': ['TbOrCa', 'Smoking', 'Bronchitis'],\n",
    "             'Travel':['Smoking'],\n",
    "             'Smoking': ['Travel'],\n",
    "             'Bronchitis':['Cancer', 'Smoking']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_clean_df(df_lags, k2_return):\n",
    "  df_clean = pd.DataFrame(data=np.zeros([len(df_lags.columns),len(df_lags.columns)], dtype=float), columns= df_lags.columns, index= df_lags.columns) \n",
    "\n",
    "  for key, values in k2_return.items():\n",
    "    node_son = key\n",
    "    lista_son = te. get_lags_ances_df(df_lags, node_son,0, {}, [], {})[1]\n",
    "\n",
    "    for node in values:\n",
    "      split_name = node.split('-')\n",
    "      node_ref = split_name[0]\n",
    "      lag = split_name[1].split('_')[1]\n",
    "      idx_ref = int(split_name[1].split('_')[0])\n",
    "\n",
    "      count = 0\n",
    "      path_list = lista_son[node_ref][idx_ref][::-1]\n",
    "\n",
    "      if len(lista_son[node_ref][idx_ref][::-1]) == 1:\n",
    "          print('here ',node_ref, node_son)\n",
    "          df_clean.at[node_ref,node_son] = 1\n",
    "      while count < len(path_list) -1:\n",
    "        print('here ',node_ref, node_son)\n",
    "        df_clean.at[path_list[count], path_list[count+1]] = 1\n",
    "        count +=1\n",
    "      if not len(lista_son[node_ref][idx_ref][::-1]) == 1:\n",
    "        df_clean.at[node_ref, path_list[0]] = 1\n",
    "\n",
    "  return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         214 function calls (207 primitive calls) in 0.000 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 enum.py:284(__call__)\n",
      "        2    0.000    0.000    0.000    0.000 enum.py:526(__new__)\n",
      "        1    0.000    0.000    0.000    0.000 enum.py:836(__and__)\n",
      "        1    0.000    0.000    0.000    0.000 re.py:232(compile)\n",
      "        1    0.000    0.000    0.000    0.000 re.py:271(_compile)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:249(_compile_charset)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:276(_optimize_charset)\n",
      "        2    0.000    0.000    0.000    0.000 sre_compile.py:453(_get_iscased)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:461(_get_literal_prefix)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:492(_get_charset_prefix)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:536(_compile_info)\n",
      "        2    0.000    0.000    0.000    0.000 sre_compile.py:595(isstring)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:598(_code)\n",
      "      3/1    0.000    0.000    0.000    0.000 sre_compile.py:71(_compile)\n",
      "        1    0.000    0.000    0.000    0.000 sre_compile.py:759(compile)\n",
      "        3    0.000    0.000    0.000    0.000 sre_parse.py:111(__init__)\n",
      "        7    0.000    0.000    0.000    0.000 sre_parse.py:160(__len__)\n",
      "       18    0.000    0.000    0.000    0.000 sre_parse.py:164(__getitem__)\n",
      "        7    0.000    0.000    0.000    0.000 sre_parse.py:172(append)\n",
      "      3/1    0.000    0.000    0.000    0.000 sre_parse.py:174(getwidth)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:224(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 sre_parse.py:233(__next)\n",
      "        2    0.000    0.000    0.000    0.000 sre_parse.py:249(match)\n",
      "        6    0.000    0.000    0.000    0.000 sre_parse.py:254(get)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:286(tell)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:417(_parse_sub)\n",
      "        2    0.000    0.000    0.000    0.000 sre_parse.py:475(_parse)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:76(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 sre_parse.py:81(groups)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:903(fix_flags)\n",
      "        1    0.000    0.000    0.000    0.000 sre_parse.py:919(parse)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _sre.compile}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.exec}\n",
      "       25    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "    29/26    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "        9    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method builtins.ord}\n",
      "       48    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'find' of 'bytearray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
