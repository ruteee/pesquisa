{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rute/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from graphviz import Digraph\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transferEntropy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_df_valid_corrs(df, limit):\n",
    "    df_valid = pd.DataFrame(np.zeros([df.shape[0], df.shape[1]], dtype=int), columns = df.columns, index= df.columns)\n",
    "    for row in df.columns:\n",
    "        for col in df.columns:\n",
    "            if df[row][col] > limit:\n",
    "                df_valid[row][col] = 1\n",
    "                \n",
    "    return df_valid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Receving data\n",
    "dist6_novo = pd.read_csv(\"dist6_3horas_sig/alm_seq.csv\")\n",
    "dist = dist6_novo[['xmeas%02d_low' % x for x in [1,2,3,8,9,21]] + ['xmeas%02d_high' % x for x in [1,2,3,8,9,21]]]\n",
    "dist6_novo.drop('tout', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moving mean app\n",
    "window = 2 #window of moving mean\n",
    "\n",
    "roll  = dist.rolling(window).mean() \n",
    "roll.dropna(inplace=True)\n",
    "roll = roll.round(decimals=0).copy()\n",
    "roll.reset_index(drop=True, inplace=True)\n",
    "\n",
    "dist = roll.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths\n",
    "\n",
    "cen1 = \"cenarios_cba/media_movel/mean_2/cen1/\"\n",
    "cen2 = \"cenarios_cba/media_movel/mean_2/cen2/\"\n",
    "cen3 = \"cenarios_cba/media_movel/mean_2/cen3/\"\n",
    "cen4 = \"cenarios_cba/media_movel/mean_2/cen4/\"\n",
    "cen5 = \"cenarios_cba/media_movel/mean_2/cen5/\"\n",
    "cen6 = \"cenarios_cba/media_movel/mean_2/cen6/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.014245\n",
      "Qtd_relacoes  3.0\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "te_matrix_1_1 = transferEntropy_case(dist, 0.99, 1, 1, 1)\n",
    "end = time.clock()\n",
    "t1 = end-start\n",
    "\n",
    "t = np.mean(te_matrix_1_1) + 3*np.std(te_matrix_1_1)\n",
    "df_te_1_1 =  pd.DataFrame(te_matrix_1_1, columns = dist.columns, index= dist.columns)\n",
    "vld_cor_1_1 = generate_df_valid_corrs(df_te_1_1, t)\n",
    "\n",
    "df_te_1_1.to_csv(cen1+\"k1_l1_h1_corrs.csv\")\n",
    "vld_cor_1_1.to_csv(cen1 +\"k1_l1_h1_sel_corrs.csv\")\n",
    "\n",
    "qtd_relacoes = generate_df_valid_corrs(df_te_1_1, t).apply(pd.value_counts).loc[1].sum()\n",
    "print(\"Qtd_relacoes \", qtd_relacoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.626296\n",
      "Qtd_relacoes  2.0\n"
     ]
    }
   ],
   "source": [
    "te_matrix_3_1 = transferEntropy_case(dist, 0.99, 3, 1, 1)\n",
    "t = np.mean(te_matrix_3_1) + 3*np.std(te_matrix_3_1)\n",
    "\n",
    "df_te_3_1 =  pd.DataFrame(te_matrix_3_1, columns = dist.columns, index= dist.columns)\n",
    "vld_cor_3_1 = generate_df_valid_corrs(df_te_3_1, t)\n",
    "\n",
    "df_te_3_1.to_csv(cen1+\"k3_l1_h1_corrs.csv\")\n",
    "vld_cor_3_1.to_csv(cen1 +\"k3_l1_h1_sel_corrs.csv\")\n",
    "\n",
    "qtd_relacoes = generate_df_valid_corrs(df_te_3_1, t).apply(pd.value_counts).loc[1].sum()\n",
    "print(\"Qtd_relacoes \", qtd_relacoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140.245052\n",
      "Qtd_relacoes  4.0\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "te_matrix_6_1 = transferEntropy_case(dist, 0.99, 6, 1, 1)\n",
    "end = time.clock()\n",
    "t3 = end-start\n",
    "\n",
    "t = np.mean(te_matrix_6_1) + 3*np.std(te_matrix_6_1)\n",
    "\n",
    "df_te_6_1 =  pd.DataFrame(te_matrix_6_1, columns = dist.columns, index= dist.columns)\n",
    "vld_cor_6_1 = generate_df_valid_corrs(df_te_6_1, t)\n",
    "\n",
    "df_te_6_1.to_csv(cen1+\"k6_l1_h1_corrs.csv\")\n",
    "vld_cor_3_1.to_csv(cen1 +\"k6_l1_h1_sel_corrs.csv\")\n",
    "\n",
    "qtd_relacoes = generate_df_valid_corrs(df_te_6_1, t).apply(pd.value_counts).loc[1].sum()\n",
    "print(\"Qtd_relacoes \", qtd_relacoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cenário 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.17785900000001\n",
      "Qtd_relacoes  4.0\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "te_matrix_1_3 = transferEntropy_case(dist, 0.99, 1, 3, 1)\n",
    "end = time.clock()\n",
    "t4 = end - start\n",
    "\n",
    "t = np.mean(te_matrix_1_3) + 3*np.std(te_matrix_1_3)\n",
    "\n",
    "df_te_1_3 =  pd.DataFrame(te_matrix_1_3, columns = dist.columns, index= dist.columns)\n",
    "vld_cor_1_3 = generate_df_valid_corrs(df_te_1_3, t)\n",
    "\n",
    "df_te_1_3.to_csv(cen2+\"k1_l3_h1_corrs.csv\")\n",
    "vld_cor_1_3.to_csv(cen2 +\"k1_l3_h1_sel_corrs.csv\")\n",
    "\n",
    "qtd_relacoes = generate_df_valid_corrs(df_te_1_3, t).apply(pd.value_counts).loc[1].sum()\n",
    "print(\"Qtd_relacoes \", qtd_relacoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140.61891200000002\n",
      "Qtd_relacoes  6.0\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "te_matrix_1_6 = transferEntropy_case(dist, 0.99, 1, 6, 1)\n",
    "end = time.clock()\n",
    "t5 = end-start\n",
    "\n",
    "t = np.mean(te_matrix_1_6) + 3*np.std(te_matrix_1_6)\n",
    "\n",
    "df_te_1_6 =  pd.DataFrame(te_matrix_1_6, columns = dist.columns, index= dist.columns)\n",
    "vld_cor_1_6 = generate_df_valid_corrs(df_te_1_6, t)\n",
    "\n",
    "df_te_1_6.to_csv(cen2+\"k1_l6_h1_corrs.csv\")\n",
    "vld_cor_1_6.to_csv(cen2+\"k1_l6_h1_sel_corrs.csv\")\n",
    "\n",
    "qtd_relacoes = generate_df_valid_corrs(df_te_1_6, t).apply(pd.value_counts).loc[1].sum()\n",
    "print(\"Qtd_relacoes \", qtd_relacoes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cenário 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.17181800000003\n",
      "Qtd_relacoes  2.0\n",
      "53.17193099999997\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "te_matrix_h3 = transferEntropy_case(dist, 0.99, 1, 1, 3)\n",
    "end = time.clock()\n",
    "t6 = end-start\n",
    "\n",
    "t = np.mean(te_matrix_h3) + 3*np.std(te_matrix_h3)\n",
    "\n",
    "df_te_h3 =  pd.DataFrame(te_matrix_h3, columns = dist.columns, index= dist.columns)\n",
    "vld_cor_h3 = generate_df_valid_corrs(df_te_h3, t)\n",
    "\n",
    "df_te_h3.to_csv(cen3+\"k1_l1_h3_corrs.csv\")\n",
    "vld_cor_h3.to_csv(cen3+\"k1_l1_h3_sel_corrs.csv\")\n",
    "\n",
    "qtd_relacoes = generate_df_valid_corrs(df_te_h3, t).apply(pd.value_counts).loc[1].sum()\n",
    "print(\"Qtd_relacoes \", qtd_relacoes)\n",
    "print(t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.899040000000014\n",
      "Qtd_relacoes  4.0\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "te_matrix_h6 = transferEntropy_case(dist, 0.99, 1, 1, 6)\n",
    "end = time.clock()\n",
    "t7 = end-start\n",
    "\n",
    "t = np.mean(te_matrix_h6) + 3*np.std(te_matrix_h6)\n",
    "\n",
    "df_te_h6 =  pd.DataFrame(te_matrix_h6, columns = dist.columns, index= dist.columns)\n",
    "vld_cor_h6 = generate_df_valid_corrs(df_te_h6, t)\n",
    "\n",
    "df_te_h6.to_csv(cen3+\"k1_l1_h6_corrs.csv\")\n",
    "vld_cor_h6.to_csv(cen3+\"k1_l1_h6_sel_corrs.csv\")\n",
    "\n",
    "qtd_relacoes = generate_df_valid_corrs(df_te_h6, t).apply(pd.value_counts).loc[1].sum()\n",
    "print(\"Qtd_relacoles \", qtd_relacoes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cenário 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.514635\n",
      "Qtd_relacoes  3.0\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "te_matrix_k3_h3 = transferEntropy_case(dist, 0.99, 3, 1, 3)\n",
    "end = time.clock()\n",
    "t8 = end-start\n",
    "\n",
    "t = np.mean(te_matrix_k3_h3) + 3*np.std(te_matrix_k3_h3)\n",
    "df_te_k3_h3 =  pd.DataFrame(te_matrix_k3_h3, columns = dist.columns, index= dist.columns)\n",
    "vld_k3_h3 = generate_df_valid_corrs(df_te_k3_h3, t)\n",
    "\n",
    "df_te_k3_h3.to_csv(cen4+\"k3_l1_h3_corrs.csv\")\n",
    "vld_k3_h3.to_csv(cen4+\"k3_l1_h3_sel_corrs.csv\")\n",
    "\n",
    "qtd_relacoes = generate_df_valid_corrs(df_te_k3_h3, t).apply(pd.value_counts).loc[1].sum()\n",
    "print(\"Qtd_relacoes \", qtd_relacoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.92378300000007\n",
      "Qtd_relacoes  4.0\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "te_matrix_k3_h6 = transferEntropy_case(dist, 0.99, 3, 1, 6)\n",
    "end = time.clock()\n",
    "t9 = end - start\n",
    "\n",
    "t = np.mean(te_matrix_k3_h6) + 3*np.std(te_matrix_k3_h6)\n",
    "\n",
    "df_te_k3_h6 =  pd.DataFrame(te_matrix_k3_h6, columns = dist.columns, index= dist.columns)\n",
    "vld_k3_h6 = generate_df_valid_corrs(df_te_k3_h6, t)\n",
    "\n",
    "df_te_k3_h6.to_csv(cen4+\"k3_l1_h6_corrs.csv\")\n",
    "vld_k3_h6.to_csv(cen4+\"k3_l1_h6_sel_corrs.csv\")\n",
    "\n",
    "qtd_relacoes = generate_df_valid_corrs(df_te_k3_h6, t).apply(pd.value_counts).loc[1].sum()\n",
    "print(\"Qtd_relacoes \", qtd_relacoes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134.6595480000001\n",
      "Qtd_relacoes  4.0\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "te_matrix_k6_h3 = transferEntropy_case(dist, 0.99, 6, 1, 3)\n",
    "end = time.clock()\n",
    "t10 = end - start\n",
    "\n",
    "t = np.mean(te_matrix_k6_h3) + 3*np.std(te_matrix_k6_h3)\n",
    "\n",
    "df_te_k6_h3 =  pd.DataFrame(te_matrix_k6_h3, columns = dist.columns, index= dist.columns)\n",
    "vld_k6_h3 = generate_df_valid_corrs(df_te_k6_h3, t)\n",
    "\n",
    "df_te_k6_h3.to_csv(cen4+\"k6_l1_h3_corrs.csv\")\n",
    "vld_k6_h3.to_csv(cen4+\"k6_l1_h3_sel_corrs.csv\")\n",
    "\n",
    "\n",
    "qtd_relacoes = vld_k6_h3.apply(pd.value_counts).loc[1].sum()\n",
    "print(\"Qtd_relacoes \", qtd_relacoes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134.49045\n",
      "Qtd_relacoes  4.0\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "te_matrix_k6_h6 = transferEntropy_case(dist, 0.99, 6, 1, 6)\n",
    "end = time.clock()\n",
    "t11 = end - start\n",
    "\n",
    "t = np.mean(te_matrix_k6_h6) + 3*np.std(te_matrix_k6_h6)\n",
    "\n",
    "df_te_k6_h6 =  pd.DataFrame(te_matrix_k6_h6, columns = dist.columns, index= dist.columns)\n",
    "vld_k6_h6 = generate_df_valid_corrs(df_te_k6_h6, t)\n",
    "\n",
    "df_te_k6_h6.to_csv(cen4+\"k6_l1_h6_corrs.csv\")\n",
    "vld_k6_h6.to_csv(cen4+\"k6_l1_h6_sel_corrs.csv\")\n",
    "\n",
    "qtd_relacoes = vld_k6_h6.apply(pd.value_counts).loc[1].sum()\n",
    "print(\"Qtd_relacoes \", qtd_relacoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.81741299999999\n",
      "Qtd_relacoes  4.0\n"
     ]
    }
   ],
   "source": [
    "#Cenário 5\n",
    "\n",
    "start = time.clock()\n",
    "te_matrix_l3_h3 = transferEntropy_case(dist, 0.99, 1, 3, 3)\n",
    "end = time.clock()\n",
    "\n",
    "t12 = end - start\n",
    "\n",
    "t = np.mean(te_matrix_l3_h3) + 3*np.std(te_matrix_l3_h3)\n",
    "\n",
    "df_te_l3_h3 =  pd.DataFrame(te_matrix_l3_h3, columns = dist.columns, index= dist.columns)\n",
    "vld_l3_h3 = generate_df_valid_corrs(df_te_l3_h3, t)\n",
    "\n",
    "df_te_l3_h3.to_csv(cen5+\"k1_l3_h3_corrs.csv\")\n",
    "vld_l3_h3.to_csv(cen5 + \"k1_l3_h3_sel_corrs.csv\")\n",
    "\n",
    "qtd_relacoes = vld_l3_h3.apply(pd.value_counts).loc[1].sum()\n",
    "print(\"Qtd_relacoes \", qtd_relacoes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.65041700000006\n",
      "Qtd_relacoes  5.0\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "te_matrix_l3_h6 = transferEntropy_case(dist, 0.99, 1, 3, 6)\n",
    "end = time.clock()\n",
    "\n",
    "t13 = end - start\n",
    "\n",
    "t = np.mean(te_matrix_l3_h6) + 3*np.std(te_matrix_l3_h6)\n",
    "\n",
    "df_te_l3_h6 =  pd.DataFrame(te_matrix_l3_h6, columns = dist.columns, index= dist.columns)\n",
    "vld_l3_h6 = generate_df_valid_corrs(df_te_l3_h6, t)\n",
    "\n",
    "df_te_l3_h6.to_csv(cen5+\"k1_l3_h6_corrs.csv\")\n",
    "vld_l3_h6.to_csv(cen5 + \"k1_l3_h6_sel_corrs.csv\")\n",
    "\n",
    "qtd_relacoes = vld_l3_h6.apply(pd.value_counts).loc[1].sum()\n",
    "print(\"Qtd_relacoes \", qtd_relacoes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136.00995899999998\n",
      "Qtd_relacoes  5.0\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "te_matrix_l6_h3 = transferEntropy_case(dist, 0.99, 1, 6, 3)\n",
    "end = time.clock()\n",
    "\n",
    "t14 = end-start\n",
    "\n",
    "t = np.mean(te_matrix_l6_h3) + 3*np.std(te_matrix_l6_h3)\n",
    "\n",
    "df_te_l6_h3 =  pd.DataFrame(te_matrix_l6_h3, columns = dist.columns, index= dist.columns)\n",
    "vld_l6_h3 = generate_df_valid_corrs(df_te_l6_h3, t)\n",
    "\n",
    "df_te_l6_h3.to_csv(cen5+\"k1_l6_h3_corrs.csv\")\n",
    "vld_l6_h3.to_csv(cen5+\"k1_l6_h3_sel_corrs.csv\")\n",
    "\n",
    "qtd_relacoes = vld_l6_h3.apply(pd.value_counts).loc[1].sum()\n",
    "print(\"Qtd_relacoes \", qtd_relacoes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135.52546300000017\n",
      "Qtd_relacoes  7.0\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "te_matrix_l6_h6 = transferEntropy_case(dist, 0.99, 1, 6, 6)\n",
    "end = time.clock()\n",
    "t15 = end - start\n",
    "\n",
    "t =np.mean(te_matrix_l6_h6) + 3*np.std(te_matrix_l6_h6)\n",
    "df_te_l6_h6 = pd.DataFrame(te_matrix_l6_h6, columns = dist.columns, index= dist.columns)\n",
    "vld_l6_h6 = generate_df_valid_corrs(df_te_l6_h6,t)\n",
    "\n",
    "df_te_l6_h6.to_csv(cen5+\"k1_l6_h6_corrs.csv\")\n",
    "vld_l6_h6.to_csv(cen5+\"k1_l6_h6_sel_corrs.csv\")\n",
    "\n",
    "qtd_relacoes = vld_l6_h6.apply(pd.value_counts).loc[1].sum()\n",
    "print(\"Qtd_relacoes \", qtd_relacoes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123.49764700000014\n",
      "Qtd_relacoes  5.0\n"
     ]
    }
   ],
   "source": [
    "#Cénario 6\n",
    "\n",
    "start = time.clock()\n",
    "te_matrix_k3_l3 = transferEntropy_case(dist, 0.99, 3, 3, 1)\n",
    "end = time.clock()\n",
    "t16 = end-start\n",
    "\n",
    "t = np.mean(te_matrix_k3_l3) + 3*np.std(te_matrix_k3_l3)\n",
    "\n",
    "df_te_k3_l3 = pd.DataFrame(te_matrix_k3_l3, columns = dist.columns, index= dist.columns)\n",
    "vld_k3_l3 = generate_df_valid_corrs(df_te_k3_l3,t)\n",
    "\n",
    "df_te_k3_l3.to_csv(cen6+\"k3_l3_h1_corrs.csv\")\n",
    "vld_k3_l3.to_csv(cen6+\"k3_l3_h1_sel_corrs.csv\")\n",
    "\n",
    "qtd_relacoes = vld_k3_l3.apply(pd.value_counts).loc[1].sum()\n",
    "print(\"Qtd_relacoes \", qtd_relacoes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599.6736540000002\n",
      "Qtd_relacoes  6.0\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "te_matrix_k6_l6 = transferEntropy_case(dist, 0.99, 6, 6, 1)\n",
    "end = time.clock()\n",
    "t17 = end-start\n",
    "\n",
    "t = np.mean(te_matrix_k6_l6) + 3*np.std(te_matrix_k6_l6)\n",
    "\n",
    "df_te_k6_l6 = pd.DataFrame(te_matrix_k6_l6, columns = dist.columns, index= dist.columns)\n",
    "vld_k6_l6 = generate_df_valid_corrs(df_te_k6_l6,t)\n",
    "\n",
    "df_te_k6_l6.to_csv(cen6+\"k6_l6_h1_corrs.csv\")\n",
    "vld_k6_l6.to_csv(cen6+\"k6_l6_h1_sel_corrs.csv\")\n",
    "\n",
    "qtd_relacoes = vld_k6_l6.apply(pd.value_counts).loc[1].sum()\n",
    "print(\"Qtd_relacoes \", qtd_relacoes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resampling application \n",
    "\n",
    "# df = dist_roll #df which will be resampled\n",
    "# num_gpd_samples = 10 #num of samples to be grouped \n",
    "# dist6_resamp = df.groupby(lambda i: i // num_gpd_samples).agg(lambda g: 0 if np.sum(g) < num_gpd_samples/2 else 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
