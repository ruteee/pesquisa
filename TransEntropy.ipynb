{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "almNum = 3\n",
    "ocorr = 100\n",
    "t_sample = 60\n",
    "base_hour = dt.datetime(2018, 1,9,9,0,0)\n",
    "occor_num = 0\n",
    "\n",
    "#Settings alarms\n",
    "\n",
    "a = np.zeros(1, dtype=int)\n",
    "ocorr = 10\n",
    "duration = 120 #120sec\n",
    "hour_init = base_hour\n",
    "\n",
    "b = np.zeros(1, dtype=int)\n",
    "pAb = 0.1\n",
    "delay_b = 60 #seconds\n",
    "duration_b = 120\n",
    "\n",
    "c = np.zeros(1, dtype=int)\n",
    "pAc = 0.6\n",
    "delay_c = 15 #seconds\n",
    "duration_c = 120\n",
    "\n",
    "\n",
    "#Alarm Series Generation, A (cause), B(Effect). C(Effect)\n",
    "while(occor_num < ocorr): \n",
    "    \n",
    "    #A generation - begin\n",
    "    srtd_hour = random.normalvariate(3, 1)\n",
    "    srtd_hour_begin = hour_init + dt.timedelta(hours=srtd_hour)\n",
    "    srtd_hour_end = srtd_hour_begin + dt.timedelta(seconds = duration)\n",
    "\n",
    "    idx_init_a_occor = int(math.ceil((srtd_hour_begin - base_hour).total_seconds()/t_sample))\n",
    "    idx_end_a_occor = int(math.ceil((srtd_hour_end - base_hour).total_seconds()/t_sample))\n",
    "        \n",
    "    if(idx_end_a_occor > a.size):\n",
    "            a.resize(idx_end_a_occor)\n",
    "\n",
    "    for i in np.arange(idx_init_a_occor, idx_end_a_occor + 1):\n",
    "        a[i-1] = 1\n",
    "    #A generation - end\n",
    "         \n",
    "    \n",
    "    #B generation begin\n",
    "    srtd_prob_b = random.uniform(0,1)  \n",
    "    if srtd_prob_b <= pAb:\n",
    "        srtd_hour_begin_b = srtd_hour_begin + dt.timedelta(hours = delay_b/3600)\n",
    "        srtd_hour_end_b = srtd_hour_begin_b + dt.timedelta(seconds=duration_b)\n",
    "\n",
    "        idx_init_b_occor = int(math.ceil((srtd_hour_begin_b - base_hour).total_seconds()/t_sample))\n",
    "        idx_end_b_occor = int(math.ceil((srtd_hour_begin_b - base_hour).total_seconds()/t_sample))\n",
    "\n",
    "        if(idx_end_b_occor > b.size):\n",
    "                b.resize(idx_end_b_occor)\n",
    "\n",
    "        for j in np.arange(idx_init_b_occor, idx_end_b_occor +1):\n",
    "            b[j-1] =  1  \n",
    "    #B generation end\n",
    "\n",
    "    #C generation begin\n",
    "    srtd_prob_c = random.uniform(0,1)\n",
    "    if srtd_prob_c <= pAc:\n",
    "        srtd_hour_begin_c = srtd_hour_begin + dt.timedelta(hours = delay_b/3600)\n",
    "        srtd_hour_end_c = srtd_hour_begin_c + dt.timedelta(seconds=duration_c)\n",
    "\n",
    "        idx_init_c_occor = int(math.ceil((srtd_hour_begin_c - base_hour).total_seconds()/t_sample))\n",
    "        idx_end_c_occor = int(math.ceil((srtd_hour_end_c - base_hour).total_seconds()/t_sample))\n",
    "        \n",
    "        if(idx_end_c_occor > c.size):\n",
    "            c.resize(idx_end_c_occor)\n",
    "\n",
    "        for j in np.arange(idx_init_c_occor, idx_end_c_occor +1):\n",
    "            c[j-1] = 1    \n",
    "    #C generation end\n",
    "    \n",
    "    hour_init = srtd_hour_begin\n",
    "    occor_num = occor_num + 1\n",
    "\n",
    "#Making series the same length\n",
    "max_len = max(a, b, c, key=len).size\n",
    "a = np.concatenate([a, np.zeros(max_len - a.size)])\n",
    "b = np.concatenate([b, np.zeros(max_len - b.size)])\n",
    "c = np.concatenate([c, np.zeros(max_len - c.size)])\n",
    "sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b.astype(int)\n",
    "a = a.astype(int)\n",
    "\n",
    "def joint_probability(k,l, h, a, b):\n",
    "    \n",
    "    '''\n",
    "        k B time horizon\n",
    "        l A time horizon\n",
    "        h instant in the future of serie B\n",
    "        \n",
    "        a, b array type'''\n",
    "\n",
    "    #Alarm Series A (cause), B (effect), same len\n",
    "    #tested\n",
    "    sizeSeries = a.size\n",
    "    transEntropy = 0\n",
    "    numStates = 2**(k + l  + 1)\n",
    "    combinations = list(map(list, itertools.product([0, 1], repeat=k+l+1)))\n",
    "    counting = np.zeros(numStates)\n",
    "    prob_cnjt = np.zeros(numStates)\n",
    "    a_prob_ind = []\n",
    "    b_prob_ind = []\n",
    "\n",
    "    #calculo da probabilidade conjunta p(i_sub_t+1), i_sub_t**k, j_sub_t**l)\n",
    "    inicio = np.max([k,l]) - 1\n",
    "    for i in np.arange(inicio, sizeSeries - 1):\n",
    "        for hk in np.arange(0,k):\n",
    "                b_prob_ind.append(b[i - hk])\n",
    "        for hl in np.arange(0,l):\n",
    "                a_prob_ind.append(a[i - hl])\n",
    "\n",
    "        ab = [b[i + h]] + b_prob_ind + a_prob_ind \n",
    "        index_comb = combinations.index(ab)\n",
    "        counting[index_comb] = counting[index_comb] + 1\n",
    "\n",
    "        a_prob_ind = []\n",
    "        b_prob_ind = []\n",
    "\n",
    "    total = sum(counting)\n",
    "    for i, cnt in enumerate(counting):\n",
    "        prob_cnjt[i] = cnt/total\n",
    "        \n",
    "    return prob_cnjt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joint probability evaluation p(i_t+h, i_t**k)\n",
    "#tested\n",
    "states_ith_ik = list(map(list, itertools.product([0, 1], repeat=k + 1)))\n",
    "p_jnt_ith_ik = np.zeros(2**(k+1))\n",
    "                         \n",
    "for i, state in enumerate(states_ith_ik):\n",
    "    for j, comb in enumerate(combinations):\n",
    "        if comb[0:k+1] == state:\n",
    "            p_jnt_ith_ik[i] = p_cjnt_ith_ik[i] + prob_cnjt[j]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conditional probability p(i_sub_t+h|i**k, j**l) from log2 numerator\n",
    "#tested\n",
    "\n",
    "states_i_j = list(map(list, itertools.product([0, 1], repeat=k+l)))\n",
    "\n",
    "size = int(prob_cnjt.size/2)\n",
    "conditional_num = np.zeros(2**(k+l+1))\n",
    "\n",
    "for i,state in enumerate(states_i_j):\n",
    "    index_zero = combinations.index([0] + state)\n",
    "    prob_zero = prob_cnjt[index_zero]\n",
    "   \n",
    "    index_one = combinations.index([1] + state)\n",
    "    prob_one = prob_cnjt[index_one]\n",
    "    \n",
    "    if(prob_zero + prob_one != 0):\n",
    "        conditional_num[i] = prob_zero/(prob_zero+ prob_one)\n",
    "        conditional_num[i + 2**(k+l)] = prob_one/(prob_zero+ prob_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conditional probability p(i_sub_t+h|i**k) from log2 denominator\n",
    "#tested\n",
    "\n",
    "size = int((2**(k+1))/2)\n",
    "count_zero  = 0\n",
    "count_um = 0\n",
    "conditional_den = np.zeros(2**(k+1))\n",
    "\n",
    "states_i = list(map(list, itertools.product([0, 1], repeat=k)))\n",
    "states_i_plus_h_i_k = list(map(list, itertools.product([0, 1], repeat=k+1)))\n",
    "\n",
    "\n",
    "for i, state in enumerate(states_i):\n",
    "    index_zero = states_i_plus_h_i_k.index([0] + state)\n",
    "    prob_zero = p_jnt_ith_ik[index_zero]\n",
    "\n",
    "    index_one = states_i_plus_h_i_k.index([1] + state)\n",
    "    prob_one = p_jnt_ith_ik[index_one]\n",
    "\n",
    "    if(prob_zero + prob_one != 0):\n",
    "        conditional_den[i] = prob_zero/(prob_zero+ prob_one)\n",
    "        conditional_den[i + 2**(k)] = prob_one/(prob_zero+ prob_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.99390244e-01, 1.00000000e+00, 6.09756098e-04, 0.00000000e+00])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional_den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Division of the conditionals in log2 \n",
    "#tested\n",
    "conditional_div = np.zeros(conditional_num.size)\n",
    "states_den = list(map(list, itertools.product([0, 1], repeat=1+k)))\n",
    "for j, comb in enumerate(combinations):\n",
    "    if(conditional_den[states_den.index(comb[0:k+1])] != 0):\n",
    "        conditional_div[j] = conditional_num[j]/conditional_den[states_den.index(comb[0:k+1])]            \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tranfer entropy final evaluation\n",
    "\n",
    "#log2 from the division of the conditionals -> p(i_sub_t+h|i_sub_t**k, j_sub_t**l) /p(i_sub_t+h|i_t**k)\n",
    "\n",
    "log2_div_cond = np.log2(conditional_div[conditional_div!=0])\n",
    "te = np.sum(prob_cnjt[conditional_div!=0]*log2_div_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003562598515436798"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CÃ¡lculo da probabilidade marginal i_sub_t**\n",
    "# p_marg_i_k = np.zeros(2**k)\n",
    "# estados_i = list(map(list, itertools.product([0, 1], repeat=k)))\n",
    "# for i, est_i in enumerate(estados_i):\n",
    "#     for j, comb in enumerate(combinations):\n",
    "#         if  comb[1:k+1] == est_i:\n",
    "#             p_marg_i_k[i] = p_marg_i_k[i] + prob_cnjt[j]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #CÃ¡lculo da conjunta p(ik, jl)\n",
    "# prob_cnjt_ik_jl = []\n",
    "# size = int(prob_cnjt.size/2)\n",
    "\n",
    "# for i in np.arange(0,size):\n",
    "#     prob_cnjt_ik_jl.append(prob_cnjt[i] + prob_cnjt[2**(k+l) + i])\n",
    "# prob_cnjt_ik_jl = np.asarray(prob_cnjt_ik_jl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
