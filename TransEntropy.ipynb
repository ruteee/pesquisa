{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rute/.conda/envs/pesquisa/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%reset -f\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import scipy.integrate as integrate\n",
    "\n",
    "almNum = 3\n",
    "ocorr = 100\n",
    "t_sample = 60\n",
    "base_hour = dt.datetime(2018, 1,9,9,0,0)\n",
    "occor_num = 0\n",
    "\n",
    "#Settings alarms\n",
    "a = np.zeros(1, dtype=int)\n",
    "ocorr = 10\n",
    "duration = 120 #120sec\n",
    "hour_init = base_hour\n",
    "\n",
    "b = np.zeros(1, dtype=int)\n",
    "pAb =0.7\n",
    "delay_b = 60 #seconds\n",
    "duration_b = 120\n",
    "\n",
    "c = np.zeros(1, dtype=int)\n",
    "pAc = 0.6\n",
    "delay_c = 15 #seconds\n",
    "duration_c = 120\n",
    "\n",
    "\n",
    "#Alarm Series Generation, A (cause), B(Effect). C(Effect)\n",
    "while(occor_num < ocorr): \n",
    "    \n",
    "    #A generation - begin\n",
    "    srtd_hour = random.normalvariate(3, 1)\n",
    "    srtd_hour_begin = hour_init + dt.timedelta(hours=srtd_hour)\n",
    "    srtd_hour_end = srtd_hour_begin + dt.timedelta(seconds = duration)\n",
    "\n",
    "    idx_init_a_occor = int(math.ceil((srtd_hour_begin - base_hour).total_seconds()/t_sample))\n",
    "    idx_end_a_occor = int(math.ceil((srtd_hour_end - base_hour).total_seconds()/t_sample))\n",
    "        \n",
    "    if(idx_end_a_occor > a.size):\n",
    "            a.resize(idx_end_a_occor)\n",
    "\n",
    "    for i in np.arange(idx_init_a_occor, idx_end_a_occor + 1):\n",
    "        a[i-1] = 1\n",
    "    #A generation - end\n",
    "         \n",
    "    \n",
    "    #B generation begin\n",
    "    srtd_prob_b = random.uniform(0,1)  \n",
    "    if srtd_prob_b <= pAb:\n",
    "        srtd_hour_begin_b = srtd_hour_begin + dt.timedelta(hours = delay_b/3600)\n",
    "        srtd_hour_end_b = srtd_hour_begin_b + dt.timedelta(seconds=duration_b)\n",
    "\n",
    "        idx_init_b_occor = int(math.ceil((srtd_hour_begin_b - base_hour).total_seconds()/t_sample))\n",
    "        idx_end_b_occor = int(math.ceil((srtd_hour_end_b - base_hour).total_seconds()/t_sample))\n",
    "\n",
    "        if(idx_end_b_occor > b.size):\n",
    "                b.resize(idx_end_b_occor)\n",
    "\n",
    "        for j in np.arange(idx_init_b_occor, idx_end_b_occor +1):\n",
    "            b[j-1] =  1  \n",
    "    #B generation end\n",
    "\n",
    "    #C generation begin\n",
    "    srtd_prob_c = random.uniform(0,1)\n",
    "    if srtd_prob_c <= pAc:\n",
    "        srtd_hour_begin_c = srtd_hour_begin + dt.timedelta(hours = delay_b/3600)\n",
    "        srtd_hour_end_c = srtd_hour_begin_c + dt.timedelta(seconds=duration_c)\n",
    "\n",
    "        idx_init_c_occor = int(math.ceil((srtd_hour_begin_c - base_hour).total_seconds()/t_sample))\n",
    "        idx_end_c_occor = int(math.ceil((srtd_hour_end_c - base_hour).total_seconds()/t_sample))\n",
    "        \n",
    "        if(idx_end_c_occor > c.size):\n",
    "            c.resize(idx_end_c_occor)\n",
    "\n",
    "        for j in np.arange(idx_init_c_occor, idx_end_c_occor +1):\n",
    "            c[j-1] = 1    \n",
    "    #C generation end\n",
    "    \n",
    "    hour_init = srtd_hour_begin\n",
    "    occor_num = occor_num + 1\n",
    "\n",
    "#Making series the same length\n",
    "max_len = max(a, b, c, key=len).size\n",
    "a = np.concatenate([a, np.zeros(max_len - a.size)])\n",
    "b = np.concatenate([b, np.zeros(max_len - b.size)])\n",
    "c = np.concatenate([c, np.zeros(max_len - c.size)])\n",
    "sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Significance test\n",
    "def significance_test(a,b,k,l,h,sup_lim, n):\n",
    "    '''\n",
    "        significance_test(a,b,k,l,h,sup_lim, n)\n",
    "    '''\n",
    "    transferEntropies = []\n",
    "    \n",
    "    np.random.seed(int(time.time()))\n",
    "    for i in np.arange(0,n):\n",
    "        np.random.shuffle(a)\n",
    "        transferEntropies.append(te(k,l,h,a[:],b))\n",
    "    kde = sm.nonparametric.KDEUnivariate(transferEntropies)\n",
    "    kde.fit()\n",
    "    \n",
    "    lvl_sig = kde.icdf[get_lim_index(kde.cdf, sup_lim)]\n",
    "    return lvl_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lim_index(cdf, lim):\n",
    "    summation = 0\n",
    "    index = 0\n",
    "    for i in np.arange(0, cdf.size):\n",
    "        if(summation < lim):\n",
    "            summation += cdf[i]\n",
    "        else:\n",
    "            index = i-1\n",
    "            break\n",
    "    return index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_probability(k,l, h, a, b):\n",
    "    '''\n",
    "        k B time horizon\n",
    "        l A time horizon\n",
    "        h instant in the future of serie B\n",
    "        \n",
    "        a, b array type'''\n",
    "\n",
    "    #Alarm Series A (cause), B (effect), same len\n",
    "    #tested\n",
    "    sizeSeries = a.size\n",
    "    transEntropy = 0\n",
    "    numStates = 2**(k + l  + 1)\n",
    "    combinations = list(map(list, itertools.product([0, 1], repeat=k+l+1)))\n",
    "    counting = np.zeros(numStates)\n",
    "    prob_cnjt = np.zeros(numStates)\n",
    "    a_prob_ind = []\n",
    "    b_prob_ind = []\n",
    "\n",
    "    #joitn probability p(i_sub_t+1), i_sub_t**k, j_sub_t**l)\n",
    "    inicio = np.max([k,l]) - 1\n",
    "    for i in np.arange(inicio, sizeSeries - h):\n",
    "        for hk in np.arange(0,k):\n",
    "                b_prob_ind.append(b[i - hk])\n",
    "        for hl in np.arange(0,l):\n",
    "                a_prob_ind.append(a[i - hl])\n",
    "\n",
    "        ab = [b[i + h]] + b_prob_ind + a_prob_ind \n",
    "        index_comb = combinations.index(ab)\n",
    "        counting[index_comb] = counting[index_comb] + 1\n",
    "\n",
    "        a_prob_ind = []\n",
    "        b_prob_ind = []\n",
    "\n",
    "    total = sum(counting)\n",
    "    for i, cnt in enumerate(counting):\n",
    "        prob_cnjt[i] = cnt/total\n",
    "        \n",
    "    return prob_cnjt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joint probability evaluation p(i_t+h, i_t**k)\n",
    "#tested\n",
    "def joint_prob_ih_ik(k,l, joint_prob_ih_ik_jl):\n",
    "    states_ith_ik = list(map(list, itertools.product([0, 1], repeat=k + 1)))\n",
    "    combinations = list(map(list, itertools.product([0, 1], repeat=k+l+1))) \n",
    "    p_jnt_ith_ik = np.zeros(2**(k+1))\n",
    "\n",
    "    for i, state in enumerate(states_ith_ik):\n",
    "        for j, comb in enumerate(combinations):\n",
    "            if comb[0:k+1] == state:\n",
    "                p_jnt_ith_ik[i] = p_jnt_ith_ik[i] + joint_prob_ih_ik_jl[j]\n",
    "    return p_jnt_ith_ik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_prob(k,l,joint_prob):\n",
    "    states = list(map(list, itertools.product([0, 1], repeat=k+l)))\n",
    "    combinations = list(map(list, itertools.product([0, 1], repeat=k+l+1)))\n",
    "\n",
    "    size = int(joint_prob.size/2)\n",
    "    conditional = np.zeros(2**(k+l+1))\n",
    "\n",
    "    for i,state in enumerate(states):\n",
    "        index_zero = combinations.index([0] + state)\n",
    "        prob_zero = joint_prob[index_zero]\n",
    "\n",
    "        index_one = combinations.index([1] + state)\n",
    "        prob_one = joint_prob[index_one]\n",
    "\n",
    "        if(prob_zero + prob_one != 0):\n",
    "            conditional[i] = prob_zero/(prob_zero+ prob_one)\n",
    "            conditional[i + 2**(k+l)] = prob_one/(prob_zero+ prob_one)\n",
    "    return conditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Division of the conditionals in log2 \n",
    "#tested\n",
    "def conditional_div(k,l,conditional_num, conditional_den):\n",
    "    combinations = list(map(list, itertools.product([0, 1], repeat=k+l+1)))\n",
    "    conditional_division = np.zeros(conditional_num.size)\n",
    "    states_den = list(map(list, itertools.product([0, 1], repeat=1+k)))\n",
    "    for j, comb in enumerate(combinations):\n",
    "        if(conditional_den[states_den.index(comb[0:k+1])] != 0):\n",
    "            conditional_division[j] = conditional_num[j]/conditional_den[states_den.index(comb[0:k+1])]            \n",
    "    return conditional_division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transfer entropy final evaluation\n",
    "def te(k,l,h,a,b):\n",
    "    '''\n",
    "        transentropy a->b\n",
    "        te(k,l,h,a,b)\n",
    "        k - dimension of b\n",
    "        l - dimension of a\n",
    "        h -> instant in the future of a\n",
    "    '''\n",
    "    joint_p_ih_ik_jl = joint_probability(k,l,h,a,b)\n",
    "    joint_p_ih_ik = joint_prob_ih_ik(k,l, joint_p_ih_ik_jl)\n",
    "    \n",
    "    conditional_num = conditional_prob(k,l,joint_p_ih_ik_jl)\n",
    "    conditional_den = conditional_prob(k,0, joint_p_ih_ik)    \n",
    "    \n",
    "    div = conditional_div(k,l,conditional_num, conditional_den)\n",
    "    \n",
    "    #log2 from the division of the conditionals ->\n",
    "    #p(i_sub_t+h|i_sub_t**k, j_sub_t**l) /p(i_sub_t+h|i_t**k)\n",
    "    \n",
    "    log2_div_cond = np.log2(div[div!=0])\n",
    "    te = np.sum(joint_p_ih_ik_jl[div!=0]*log2_div_cond)\n",
    "    \n",
    "    return te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02962269557037785"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = b.astype(int)\n",
    "a = a.astype(int)\n",
    "\n",
    "te(1,1,1,a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example with disturb number 4 from Tennesse Eastman\n",
    "\n",
    "dist4 = pd.read_csv('dist_4.csv')\n",
    "low = dist4[dist4.columns[1:47]]\n",
    "high = dist4[dist4.columns[74:120]]\n",
    "df_22 = pd.concat([low,high], axis=1)\n",
    "j = df_22['xmeas46_high'].reset_index(drop=True)\n",
    "i = df_22['xmeas09_high'].reset_index(drop=True)\n",
    "\n",
    "te_val = te(1,1,1,j,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_lvl = significance_test(j,i,1,1,1,0.95, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significance level 3.6778233825238806e-05\n",
      "te 0.0006153474130927704\n"
     ]
    }
   ],
   "source": [
    "print('Significance level', sig_lvl)\n",
    "print('te', te_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_val > sig_lvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2005788668236055e-05 2.1943808793776083e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example with disturb 10 TE\n",
    "dist10 = pd.read_csv('dist10.csv')\n",
    "dist10.head()\n",
    "\n",
    "j = dist10['xmeas45_low'].reset_index(drop=True)\n",
    "i = dist10['xmeas19_low'].reset_index(drop=True)\n",
    "\n",
    "te_val = te(1,1,1,j,i)\n",
    "sig_lvl = significance_test(j,i,1,1,1,0.95, 100)\n",
    "\n",
    "print(te_val, sig_lvl)\n",
    "te_val > sig_lvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rute/.conda/envs/pesquisa/lib/python3.6/site-packages/statsmodels/sandbox/nonparametric/kernels.py:204: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  w = 1. / (h * n) * np.sum(self((xs-x)/h), axis=0)\n",
      "/home/rute/.conda/envs/pesquisa/lib/python3.6/site-packages/statsmodels/sandbox/nonparametric/kernels.py:204: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  w = 1. / (h * n) * np.sum(self((xs-x)/h), axis=0)\n",
      "/home/rute/.conda/envs/pesquisa/lib/python3.6/site-packages/statsmodels/sandbox/nonparametric/kernels.py:204: RuntimeWarning: invalid value encountered in multiply\n",
      "  w = 1. / (h * n) * np.sum(self((xs-x)/h), axis=0)\n",
      "/home/rute/.conda/envs/pesquisa/lib/python3.6/site-packages/scipy/integrate/quadpack.py:364: IntegrationWarning: The occurrence of roundoff error is detected, which prevents \n",
      "  the requested tolerance from being achieved.  The error may be \n",
      "  underestimated.\n",
      "  warnings.warn(msg, IntegrationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.534994808802064e-06 7.23296811520082e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example with disturb 10 TE\n",
    "dist21 = pd.read_csv('dist21.csv')\n",
    "dist21.head()\n",
    "\n",
    "j = dist10['xmeas01_high'].reset_index(drop=True)\n",
    "i = dist10['xmeas09_low'].reset_index(drop=True)\n",
    "\n",
    "te_val = te(1,1,1,j,i)\n",
    "sig_lvl = significance_test(j,i,1,1,1,0.95, 100)\n",
    "\n",
    "print(te_val, sig_lvl)\n",
    "te_val > sig_lvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joint probablity for functions test\n",
    "#joint_p_ih_ik_jl = np.array([0.97322404,0.00546448,0.00491803,0,0,0.00546448, 0.00546448, 0.00546448])\n",
    "\n",
    "#aproximate results for this test\n",
    "\n",
    "#p(ith, ik)\n",
    "#jnt_p_ih_ik = [0.97868852,0.00491803,0.00546448,0.0109286] \n",
    "\n",
    "#p(i_t+h|i**k, j**l)\n",
    "#cond_p_ih_ik_jl =  [1,0.5,0.4736841094123,0,0,0.5, 0.52631589085076,1]\n",
    "\n",
    "#p(i_th|i_k)\n",
    "#cond_p_ih_ik = [0.994711793480152,0.31035179088550,0.0552469991962,0.68964820911449]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
