{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2BVRzkJYvvww"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime as dt\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "#import statsmodels.api as sm\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from graphviz import Digraph\n",
    "from scipy.ndimage import shift\n",
    "#import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "n1Getoki4DUF",
    "outputId": "fc272523-0489-40ec-deb9-51ae07578b85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in /home/rute/anaconda3/envs/pesquisa/lib/python3.7/site-packages (0.8.4)\r\n"
     ]
    }
   ],
   "source": [
    "# https://pypi.python.org/pypi/pydot\n",
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /home/rute/anaconda3/envs/pesquisa/lib/python3.7/site-packages (18.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MENjzHQfvvwz"
   },
   "outputs": [],
   "source": [
    "def get_lim_index(cdf, lim):\n",
    "    summation = 0\n",
    "    index = 0\n",
    "    for i in np.arange(0, cdf.size):\n",
    "        if cdf[i] > lim:\n",
    "            index = i\n",
    "            break\n",
    "    return index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "59-3a3e3vvw1"
   },
   "outputs": [],
   "source": [
    "def surrogate(a):\n",
    "    a_diff = np.diff(a)\n",
    "    begin = np.where(a_diff > 0)[0]\n",
    "    end = np.where(a_diff < 0)[0]\n",
    "    \n",
    "    if begin.size > end.size:\n",
    "        end = np.append(end, a.size)\n",
    "    elif begin.size < end.size:\n",
    "        begin = np.insert(begin, 0, 0) \n",
    "    elif begin.size == 0 and end.size == 0:\n",
    "        return a.copy()\n",
    "    elif np.all(begin > end):\n",
    "        begin = np.insert(begin, 0, 0)\n",
    "        end = np.append(end, a.size)\n",
    "    \n",
    "    n_seq = np.max([begin.size, end.size])\n",
    "    a_surr = np.zeros(a.shape)\n",
    "    p_seq = np.random.randint(0, a.size - max(end - begin), size=n_seq)\n",
    "    for i in np.random.permutation(n_seq):\n",
    "        len_seq = end[i] - begin[i]\n",
    "        a_surr[p_seq[i]:p_seq[i] + len_seq] = a[begin[i]:end[i]]\n",
    "    return a_surr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xITmxUD-vvw3"
   },
   "outputs": [],
   "source": [
    "#Method using stats model kde to return transfer etnropy value limit. That is, the 'x' value corresponding to P95\n",
    "def significance_test(k,l,h,sup_lim, n, a,b):\n",
    "    '''\n",
    "        significance_test(a,b,k,l,h,sup_lim, n)\n",
    "    '''\n",
    "    transferEntropies = []    \n",
    "    \n",
    "    np.random.seed(int(time.time()))\n",
    "    for i in np.arange(0,n):\n",
    "        surrogate_a = surrogate(a.copy())\n",
    "        transferEntropies.append(te(k,l,h,surrogate_a[:],b, 'serie_a', 'serie_b'))\n",
    "        \n",
    "    kde = sm.nonparametric.KDEUnivariate(transferEntropies)\n",
    "    kde.fit()\n",
    "    \n",
    "    \n",
    "    lvl_sig = kde.icdf[get_lim_index(kde.cdf, sup_lim)]\n",
    "    return lvl_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8H540fy4vvw4"
   },
   "outputs": [],
   "source": [
    "##for paper test\n",
    "def joint_probability_new(k,l,h, a, b, lbl_a, lbl_b):\n",
    "    '''\n",
    "        k B time horizon\n",
    "        l A time horizon\n",
    "        h instant in the future of serie B\n",
    "        \n",
    "        \n",
    "        a, b array type'''\n",
    "    \n",
    "    numStates=2**(k+l+1)\n",
    "    combinations = list(map(list, itertools.product([0, 1], repeat=k+l+1)))\n",
    "    prob_cnjt = np.zeros(numStates)\n",
    "    \n",
    "    #Alarm Series A (cause), B (effect), same len\n",
    "    #teste   \n",
    "\n",
    "    matrix_nova = np.matrix([b[1:],b[:-1],a[:-1]]).T\n",
    "    df = pd.DataFrame(matrix_nova, columns = ['b_ftr', lbl_b, lbl_a])\n",
    "    gpd = df.groupby(['b_ftr', lbl_b, lbl_a], as_index=False).size().reset_index(name='Count')\n",
    "    total = sum(gpd['Count'])\n",
    "    \n",
    "    for i in np.arange(0,gpd.shape[0]):\n",
    "        comb = [e for e in gpd.iloc[i][0:3].values.tolist()]\n",
    "        idx = combinations.index(comb)\n",
    "        prob_cnjt[idx] = gpd.iloc[i]['Count']/total\n",
    "\n",
    "    return prob_cnjt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oJ1KZo1Zvvw6"
   },
   "outputs": [],
   "source": [
    "def joint_probability(k,l, h, a, b):\n",
    "    '''\n",
    "        k B time horizon\n",
    "        l A time horizon\n",
    "        h instant in the future of serie B\n",
    "        \n",
    "        a, b array type'''\n",
    "\n",
    "    #Alarm Series A (cause), B (effect), same len\n",
    "    #tested\n",
    "    sizeSeries = a.size\n",
    "    transEntropy = 0\n",
    "    numStates = 2**(k + l  + 1)\n",
    "    combinations = list(map(list, itertools.product([0, 1], repeat=k+l+1)))\n",
    "    counting = np.zeros(numStates)\n",
    "    prob_cnjt = np.zeros(numStates)\n",
    "    a_prob_ind = []\n",
    "    b_prob_ind = []\n",
    "    #joitn probability p(i_sub_t+1), i_sub_t**k, j_sub_t**l)\n",
    "    inicio = np.max([k,l]) - 1\n",
    "    for i in np.arange(inicio, sizeSeries - h):\n",
    "        for hk in np.arange(0,k):\n",
    "                b_prob_ind.append(b[i - hk])\n",
    "        for hl in np.arange(0,l):\n",
    "                a_prob_ind.append(a[i - hl])\n",
    "\n",
    "        #print(a.size, b.size, a.size -1)     \n",
    "        ab = [b[i + h]] + b_prob_ind + a_prob_ind \n",
    "        index_comb = combinations.index(ab)\n",
    "        counting[index_comb] = counting[index_comb] + 1\n",
    "\n",
    "        a_prob_ind = []\n",
    "        b_prob_ind = []\n",
    "\n",
    "    total = sum(counting)\n",
    "  \n",
    "    prob_cnjt = counting/total\n",
    "     \n",
    "    return prob_cnjt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kDxNQD_Hvvw9"
   },
   "outputs": [],
   "source": [
    "#Joint probability evaluation p(i_t+h, i_t**k)\n",
    "#tested\n",
    "def joint_prob_ih_ik(k,l, joint_prob_ih_ik_jl):\n",
    "    states_ith_ik = list(map(list, itertools.product([0, 1], repeat=k + 1)))\n",
    "    combinations = list(map(list, itertools.product([0, 1], repeat=k+l+1))) \n",
    "    p_jnt_ith_ik = np.zeros(2**(k+1))\n",
    "    \n",
    "    for i, state in enumerate(states_ith_ik):\n",
    "        for j, comb in enumerate(combinations):\n",
    "            if comb[0:k+1] == state:\n",
    "                p_jnt_ith_ik[i] = p_jnt_ith_ik[i] + joint_prob_ih_ik_jl[j]\n",
    "    return p_jnt_ith_ik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mqUnJUDcvvw_"
   },
   "outputs": [],
   "source": [
    "def conditional_prob(k,l,joint_prob):\n",
    "    states = list(map(list, itertools.product([0, 1], repeat=k+l)))\n",
    "    combinations = list(map(list, itertools.product([0, 1], repeat=k+l+1)))\n",
    "\n",
    "    size = int(joint_prob.size/2)\n",
    "    conditional = np.zeros(2**(k+l+1))\n",
    "\n",
    "    for i,state in enumerate(states):\n",
    "        index_zero = combinations.index([0] + state)\n",
    "        prob_zero = joint_prob[index_zero]\n",
    "\n",
    "        index_one = combinations.index([1] + state)\n",
    "        prob_one = joint_prob[index_one]\n",
    "\n",
    "        if(prob_zero + prob_one != 0):\n",
    "            conditional[i] = prob_zero/(prob_zero+ prob_one)\n",
    "            conditional[i + 2**(k+l)] = prob_one/(prob_zero+ prob_one)\n",
    "    return conditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MNFelkuVvvxA"
   },
   "outputs": [],
   "source": [
    "#Division of the conditionals in log2 \n",
    "#tested\n",
    "def conditional_div(k,l,conditional_num, conditional_den):\n",
    "    combinations = list(map(list, itertools.product([0, 1], repeat=k+l+1)))\n",
    "    conditional_division = np.zeros(conditional_num.size)\n",
    "    states_den = list(map(list, itertools.product([0, 1], repeat=1+k)))\n",
    "    for j, comb in enumerate(combinations):\n",
    "        if(conditional_den[states_den.index(comb[0:k+1])] != 0):\n",
    "            conditional_division[j] = conditional_num[j]/conditional_den[states_den.index(comb[0:k+1])]            \n",
    "    return conditional_division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dpGL8DlsvvxF"
   },
   "outputs": [],
   "source": [
    "#Transfer entropy final evaluation\n",
    "def te(k,l,h_window, a,b):\n",
    "    '''\n",
    "        transentropy a->b\n",
    "        te(k,l,h,a,b)\n",
    "        k - dimension of b\n",
    "        l - dimension of a\n",
    "        h -> instant in the future of a\n",
    "    '''\n",
    "    #joint_p_ih_ik_jl = joint_probability_new(k,l,h,a,b, lbl_a, lbl_b)\n",
    "    \n",
    "    te_by_h = []\n",
    "    for h in np.arange(1,h_window):\n",
    "      joint_p_ih_ik_jl = joint_probability(k,l,h,a,b)\n",
    "\n",
    "      joint_p_ih_ik = joint_prob_ih_ik(k,l, joint_p_ih_ik_jl)\n",
    "      conditional_num = conditional_prob(k,l,joint_p_ih_ik_jl)\n",
    "      conditional_den = conditional_prob(k,0, joint_p_ih_ik)    \n",
    "      div = conditional_div(k,l,conditional_num, conditional_den)\n",
    "\n",
    "      #log2 from the division of the conditionals -> #p(i_sub_t+h|i_sub_t**k, j_sub_t**l) /p(i_sub_t+h|i_t**k)\n",
    "      log2_div_cond = np.log2(div[div!=0])\n",
    "      te = np.sum(joint_p_ih_ik_jl[div!=0]*log2_div_cond)\n",
    "      \n",
    "      te_by_h.append(te)\n",
    "      lag = np.argmax(te_by_h) + 1\n",
    "    return [max(te_by_h), lag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "phi8XuryvvxI"
   },
   "outputs": [],
   "source": [
    "def transferEntropy_case(dist_df, h, k, l):\n",
    "    #start = time.clock()\n",
    "    transEntropy = np.zeros([dist_df.columns.size,dist_df.columns.size])\n",
    "    lagEntropy = np.zeros([dist_df.columns.size,dist_df.columns.size])\n",
    "    sigValues =  np.zeros([dist_df.columns.size,dist_df.columns.size])\n",
    "    for i in np.arange(0, dist_df.columns.size):\n",
    "        for j in np.arange(0, dist_df.columns.size):\n",
    "            print('trans ', dist_df.columns[i], dist_df.columns[j])\n",
    "            if(j != i + dist_df.columns.size/2 and j!=i and j != i - dist_df.columns.size/2):\n",
    "                te_result = te(k,l,h, dist_df[dist_df.columns[i]], dist_df[dist_df.columns[j]])\n",
    "                transEntropy[i][j] = te_result[0]\n",
    "                lagEntropy[i][j] = te_result[1]\n",
    "                \n",
    "            clear_output()\n",
    "    #end = time.clock()   \n",
    "    \n",
    "    #print(end - start)\n",
    "    return [transEntropy, lagEntropy]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_roll_mean(df, window):\n",
    "    roll  = df.copy().rolling(window).mean() \n",
    "    roll.dropna(inplace=True)\n",
    "    roll = roll.round(decimals=0).copy()\n",
    "    roll.reset_index(drop=True, inplace=True)\n",
    "    return roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_simple(df, eng = 'dot'):\n",
    "    edge_style = \"\"\n",
    "    g = Digraph(engine=eng)\n",
    "    in_graph = []\n",
    "    for k, row in enumerate(df.index):\n",
    "        if any(df.loc[row]):\n",
    "            g.node(str(row),row, shape='oval', fontsize='10', width='0', style='filled', fillcolor='#c9c9c9', color=\"gray\")\n",
    "            in_graph.append(row)\n",
    "\n",
    "              \n",
    "    for c, col in enumerate(df.columns):\n",
    "        if any(df[col]):\n",
    "            if col not in in_graph:\n",
    "                g.node(str(col), col, shape='oval', fontsize='10', width='0', style='filled', fillcolor='#c9c9c9', color=\"gray\") \n",
    "\n",
    "    for j, col in enumerate(df.columns):\n",
    "        for i, row in enumerate(df.index):\n",
    "            if(df[col][i]):\n",
    "                g.edge(str(row), str(col), label=str(df.at[row,col]), style= edge_style, color='black')  \n",
    "    return g "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RR3gnznz4Vx9"
   },
   "outputs": [],
   "source": [
    "def graph(df, df_lag, eng = 'dot'):\n",
    "    edge_style = \"\"\n",
    "    g = Digraph(engine=eng)\n",
    "   \n",
    "    for k, row in enumerate(df.index):\n",
    "        if any(df.iloc[k]) or any(df[row]):\n",
    "            g.node(str(k),row, shape='oval', fontsize='10', width='0', style='filled', fillcolor='#c9c9c9', color=\"gray\") \n",
    "\n",
    "    for j, col in enumerate(df.columns):\n",
    "        for i, row in enumerate(df[col]):\n",
    "            if(row):\n",
    "                te_val  = str(np.round(row, 6))\n",
    "                g.edge(str(i), str(j), label=str(df_lag[df_lag.columns[j]][i]),style= edge_style, color='dark')  \n",
    "    return g "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_from_dict(dictionary, eng = 'dot'):\n",
    "    edge_style = \"\"\n",
    "    g = Digraph(engine=eng)\n",
    "   \n",
    "    for k, i in dictionary.items():\n",
    "        g.node(str(k),k, shape='oval', fontsize='10', width='0', style='filled', fillcolor='#c9c9c9', color=\"gray\") \n",
    "        df_te.m\n",
    "    for k, i in dictionary.items():\n",
    "        for it in i:\n",
    "            g.edge(str(it), str(k), label='',style= edge_style, color='dark')  \n",
    "    return g "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t9nN9piiG0aC"
   },
   "outputs": [],
   "source": [
    "def generate_df_valid_corrs(df, limit):\n",
    "    df_valid = df.copy()\n",
    "    for row in df.columns:\n",
    "        for col in df.columns:\n",
    "            if df[row][col] < limit:\n",
    "                df_valid[row][col] = 0\n",
    "                \n",
    "    return df_valid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_df_max_info(df):\n",
    "    df_max_info = pd.DataFrame(data = np.zeros([len(df),len(df)]),columns=df.columns, index = df.columns)\n",
    "    for  i,col in enumerate(df.columns):\n",
    "        sort = df[col].sort_values(ascending=False)\n",
    "        df_max_info.loc[sort.index[0]][i] = sort[0]\n",
    "    return df_max_info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_first_diff(df):\n",
    "    dist_diff = df.diff()\n",
    "    dist_diff.clip(lower=0, inplace=True)\n",
    "    dist_diff.dropna(inplace=True)\n",
    "    dist_diff.reset_index(drop=True, inplace=True)\n",
    "    dist_diff = dist_diff.astype(int)\n",
    "    \n",
    "    return dist_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_smtc_cicle(df):\n",
    "    rm_df = df.copy()\n",
    "    for c, col in enumerate(rm_df.columns):\n",
    "        for r, row in enumerate(rm_df[col]):\n",
    "            simetric_val = rm_df[rm_df.columns[r]][c]\n",
    "            if row and simetric_val:\n",
    "                if simetric_val >= row:\n",
    "                    rm_df[col][r] = 0\n",
    "                else:\n",
    "                    simetric_val = 0\n",
    "    return rm_df\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ancestrals(lista, node, lista_nova):\n",
    "    if np.all(np.unique(lista[node]) == ['x']):\n",
    "        return lista_nova\n",
    "    \n",
    "    if not node in lista_nova:\n",
    "        lista_nova.extend([node])\n",
    "            \n",
    "    if not lista[node]:\n",
    "        return lista_nova\n",
    "    else:\n",
    "        for i,no in enumerate(lista[node]):       \n",
    "            idx = no\n",
    "            node_to_list = [lista[node][i]]\n",
    "            lista[node][i] = 'x'\n",
    "            if no == 'x':\n",
    "                continue\n",
    "            if 'x' in lista[no]:\n",
    "                get_ancestrals(lista, idx, lista_nova)   \n",
    "            elif not lista[no]:\n",
    "                lista_nova.extend(node_to_list)\n",
    "                lista[no] = ['x']\n",
    "                continue\n",
    "            else:\n",
    "                lista_nova.extend(node_to_list)\n",
    "                get_ancestrals(lista, idx, lista_nova)             \n",
    "        else:\n",
    "            return get_ancestrals(lista, node, lista_nova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_aciclic_graph(grafo_param):\n",
    "    graph_mat = copy.deepcopy(grafo_param)\n",
    "    grafo_ac = np.zeros([len(graph_mat), len(graph_mat)], dtype=float)\n",
    "    ancestrals = [[] for el in np.arange(0, len(graph_mat))]\n",
    "    \n",
    "    max_val = max(graph_mat.flatten().tolist())\n",
    "    idx_max = np.argmax(graph_mat.flatten().tolist())  \n",
    "\n",
    "    while(max_val > 0):\n",
    "        idx_row = int(np.floor(idx_max)/len(graph_mat))\n",
    "        idx_col = idx_max - len(graph_mat)*idx_row\n",
    "\n",
    "        impossible_nodes = []\n",
    "        if ancestrals[idx_row]:\n",
    "            impossible_nodes = get_ancestrals(copy.deepcopy(ancestrals),idx_row, [])\n",
    "            if not idx_col in impossible_nodes:\n",
    "                grafo_ac[idx_row, idx_col] = graph_mat[idx_row, idx_col]\n",
    "                ancestrals[idx_col] += [idx_row] \n",
    "        else:\n",
    "            ancestrals[idx_col] += [idx_row]\n",
    "            grafo_ac[idx_row,idx_col] = max_val\n",
    "\n",
    "        graph_mat[idx_row, idx_col] = 0\n",
    "        max_val = max(graph_mat.flatten().tolist())\n",
    "        idx_max = np.argmax(graph_mat.flatten())\n",
    "    return grafo_ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lags_ances(mat, idx, soma, lista_lags, ref):\n",
    "    \n",
    "    if np.all(mat[:,idx] == np.zeros(len(mat))):\n",
    "        mat[idx] =  [-1 for peso in mat[idx]]\n",
    "        return 0\n",
    "\n",
    "    for i,dad_lag in enumerate(mat[:,idx]):\n",
    "        if dad_lag != 0:\n",
    "            if not np.all(mat[i] == [-1 for peso in mat[i]]):\n",
    "                soma += dad_lag\n",
    "                lista_lags.append((str(i), soma))\n",
    "                get_lags_ances(mat, i, soma, lista_lags, ref)\n",
    "                \n",
    "                soma = 0\n",
    "\n",
    "           \n",
    "    return lista_lags\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oDS2t1TEzrOX"
   },
   "outputs": [],
   "source": [
    "dist6 = pd.read_csv(\"dist6_3horas_sig/alm_seq.csv\")\n",
    "dist = dist6[['xmeas%02d_low' % x for x in [1,2,3,8,9,21]] + ['xmeas%02d_high' % x for x in [1,2,3,8,9,21]]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying 5 samples mooving mean\n",
    "df_mean5 = apply_roll_mean(dist, 5)\n",
    "df_mean5.to_csv(\"resultados_defesa/alm_seq_m5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_roc = 0.01816308533330481\n",
    "t_roc2 = 0.055674922579944816\n",
    "df_ltd = generate_df_valid_corrs(df_te, t_roc)\n",
    "df_ltd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lags_ances_df(mat,idx, soma, dict_lags, lista, dict_caminhos):\n",
    "    lista.append(idx)\n",
    "    if np.all(mat[idx] == np.zeros(len(mat))):\n",
    "        return [dict_lags,dict_caminhos]\n",
    "    for i,dad_lag in enumerate(mat[idx]):\n",
    "        if dad_lag > 0:\n",
    "          \n",
    "            soma += dad_lag\n",
    "            try:\n",
    "                dict_lags[mat.columns[i]].append(soma)\n",
    "                dict_caminhos[mat.columns[i]].append(lista)\n",
    "            except:\n",
    "                dict_lags[mat.columns[i]] = [soma]\n",
    "                dict_caminhos[mat.columns[i]]= [lista]\n",
    "        \n",
    "            get_lags_ances_df(mat, mat.columns[i], soma, dict_lags, lista[:], dict_caminhos)\n",
    "            soma -= dad_lag\n",
    "            \n",
    "    return [dict_lags, dict_caminhos] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building DF from te matrix\n",
    "t = np.mean(te_matrix[0]) + 3*np.std(te_matrix[0])\n",
    "df_te = pd.DataFrame(te_matrix[0], columns = dist.columns, index= dist.columns)\n",
    "df_te_lag = pd.DataFrame(te_matrix[1], columns = dist.columns, index= dist.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_shifts(nodes, mat):\n",
    "    dic = {}\n",
    "    for node in nodes:\n",
    "        mat_cp = mat.copy()\n",
    "#         if not np.all(mat_cp[node] == np.zeros(len(mat_cp))):\n",
    "        dic[node] = get_lags_ances_df(mat_cp, node, 0, {}, [],{})[0]\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen_tree_from_lags(dici):\n",
    "    tree_k2 = {}\n",
    "    for key_son, value in dici.items():    \n",
    "        if value:\n",
    "            for key_dad, value_dad in value.items():\n",
    "                for i, value in enumerate(value_dad):\n",
    "                    try:\n",
    "                        tree_k2[key_son].append(key_dad+\"-\"+str(i)+\"_\"+str(int(value)))\n",
    "                    except:\n",
    "                         tree_k2[key_son] = [key_dad+\"-\"+str(i)+\"_\"+str(int(value))]\n",
    "                            \n",
    "                    tree_k2[key_dad+\"-\"+str(i)+\"_\"+str(int(value))] = []\n",
    "        else:\n",
    "            tree_k2[key_son] = []\n",
    "    return tree_k2  \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_df_iteration(df, node, dict_lag):\n",
    "    df_gen = df.copy()\n",
    "    if dict_lag[node]:\n",
    "        for key_dad, values_dad in dict_lag[node].items():\n",
    "            for i, val in enumerate(dict_lag[node][key_dad]): \n",
    "                df_gen[key_dad+\"-\"+str(i)+\"_\"+str(int(val))] = shift(df_gen[key_dad], int(val), order=0, mode='constant', cval=np.NaN)\n",
    "    df_gen.dropna(inplace=True)\n",
    "    return df_gen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lags_final  = df_te_lag[df_graph_ltd_ac > 0].fillna(0)\n",
    "df_lags_final.to_csv('resultados_defesa/df_lags_ltd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gen_df_iteration(df_mean5, 'xmeas01_high', dict_all_lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_all_lags = get_all_shifts(df_lags_final.columns, df_lags_final.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"229pt\" height=\"392pt\"\n",
       " viewBox=\"0.00 0.00 228.89 392.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 388)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-388 224.8881,-388 224.8881,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"#c9c9c9\" stroke=\"#c0c0c0\" cx=\"87.5611\" cy=\"-366\" rx=\"43.6222\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"87.5611\" y=\"-363.5\" font-family=\"Times,serif\" font-size=\"10.00\" fill=\"#000000\">xmeas01_low</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>5</title>\n",
       "<ellipse fill=\"#c9c9c9\" stroke=\"#c0c0c0\" cx=\"43.5611\" cy=\"-105\" rx=\"43.6222\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"43.5611\" y=\"-102.5\" font-family=\"Times,serif\" font-size=\"10.00\" fill=\"#000000\">xmeas21_low</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;5 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M83.0814,-347.8614C76.0724,-318.8916 62.4962,-260.3142 54.5611,-210 50.5004,-184.2525 47.5567,-154.7088 45.7421,-133.5321\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"49.2071,-132.9632 44.8961,-123.2851 42.2308,-133.5392 49.2071,-132.9632\"/>\n",
       "<text text-anchor=\"middle\" x=\"73.0611\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">41.0</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>10</title>\n",
       "<ellipse fill=\"#c9c9c9\" stroke=\"#c0c0c0\" cx=\"108.5611\" cy=\"-192\" rx=\"45.1548\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"108.5611\" y=\"-189.5\" font-family=\"Times,serif\" font-size=\"10.00\" fill=\"#000000\">xmeas09_high</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;10 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>0&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M88.6445,-347.7386C90.0013,-326.7517 92.6351,-291.3011 96.5611,-261 98.3187,-247.4345 100.8489,-232.4666 103.1333,-219.9486\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"106.5784,-220.5667 104.972,-210.0943 99.6971,-219.2827 106.5784,-220.5667\"/>\n",
       "<text text-anchor=\"middle\" x=\"109.0611\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">49.0</text>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>11</title>\n",
       "<ellipse fill=\"#c9c9c9\" stroke=\"#c0c0c0\" cx=\"175.5611\" cy=\"-279\" rx=\"45.1548\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"175.5611\" y=\"-276.5\" font-family=\"Times,serif\" font-size=\"10.00\" fill=\"#000000\">xmeas21_high</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;11 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>0&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M104.5283,-349.2255C117.7981,-336.1066 136.4235,-317.6928 151.2731,-303.012\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"153.9952,-305.2425 158.6459,-295.723 149.0738,-300.2646 153.9952,-305.2425\"/>\n",
       "<text text-anchor=\"middle\" x=\"145.5611\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">5.0</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>6</title>\n",
       "<ellipse fill=\"#c9c9c9\" stroke=\"#c0c0c0\" cx=\"123.5611\" cy=\"-18\" rx=\"45.1548\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"123.5611\" y=\"-15.5\" font-family=\"Times,serif\" font-size=\"10.00\" fill=\"#000000\">xmeas01_high</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M56.617,-87.4706C64.3857,-77.3775 74.6357,-64.6275 84.5611,-54 88.4133,-49.8753 92.6547,-45.6635 96.8786,-41.6424\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"99.4358,-44.0438 104.3746,-34.6705 94.6685,-38.9181 99.4358,-44.0438\"/>\n",
       "<text text-anchor=\"middle\" x=\"97.0611\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">28.0</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;5 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>10&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M95.4073,-174.3943C86.007,-161.8122 73.2115,-144.6859 62.6843,-130.5957\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"65.2626,-128.1989 56.4734,-122.2827 59.6548,-132.3886 65.2626,-128.1989\"/>\n",
       "<text text-anchor=\"middle\" x=\"93.0611\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">18.0</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;6 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>10&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M110.138,-173.7078C112.7556,-143.3436 118.016,-82.3226 121.1174,-46.3464\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"124.6334,-46.3108 122.0053,-36.0471 117.6592,-45.7095 124.6334,-46.3108\"/>\n",
       "<text text-anchor=\"middle\" x=\"129.0611\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">47.0</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;6 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>11&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M173.888,-260.7656C170.4745,-226.3749 161.6379,-149.7498 145.5611,-87 142.0504,-73.2976 137.3767,-58.3131 133.2401,-45.8195\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"136.4391,-44.3524 129.929,-35.9937 129.8056,-46.5878 136.4391,-44.3524\"/>\n",
       "<text text-anchor=\"middle\" x=\"172.0611\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">46.0</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;10 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>11&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M158.888,-261.8967C153.4796,-256.069 147.5834,-249.4052 142.5611,-243 136.4853,-235.2514 130.3598,-226.4413 125.0142,-218.3494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"127.9358,-216.4219 119.559,-209.9349 122.0621,-220.2298 127.9358,-216.4219\"/>\n",
       "<text text-anchor=\"middle\" x=\"155.0611\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">19.0</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f0371cccac8>"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph(df_graph_ltd_ac, df_lags_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "##transformar em função\n",
    "\n",
    "lista_9 = get_lags_ances_df(df_lags_final, 'xmeas01_high',0, {}, [], {})[1]\n",
    "\n",
    "df_clean = pd.DataFrame(data=np.zeros([len(df_lags_final.columns),len(df_lags_final.columns)], dtype=float), columns= df_lags_final.columns, index= df_lags_final.columns) \n",
    "\n",
    "\n",
    "count = 0\n",
    "node_ref = 'xmeas09_high'\n",
    "idx_ref = 0\n",
    "node_son = 'xmeas01_high'\n",
    "\n",
    "path_list = lista_9[node_ref][idx_ref][::-1]\n",
    "while count < len(lista_9[node_ref][idx_ref][::-1]) -1:\n",
    "\n",
    "    if len(lista_9[node_ref][idx_ref][::-1]) == 1:\n",
    "        df_clean.at[node_ref,node_son] = 1\n",
    "    else:\n",
    "        df_clean.at[path_list[count], path_list[count+1]] = 1\n",
    "    count +=1\n",
    "     \n",
    "df_clean.at[node_ref, path_list[0]] = 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "### teste sintetico\n",
    "\n",
    "\n",
    "almNum = 3\n",
    "ocorr = 100\n",
    "t_sample = 60\n",
    "base_hour = dt.datetime(2018, 1,9,9,0,0)\n",
    "occor_num = 0\n",
    "\n",
    "#Settings alarms\n",
    "a = np.zeros(1, dtype=int)\n",
    "ocorr = 10\n",
    "duration = 120 #120sec\n",
    "hour_init = base_hour\n",
    "\n",
    "b = np.zeros(1, dtype=int)\n",
    "pAb =0.8\n",
    "delay_b = 60 #seconds\n",
    "duration_b = 120\n",
    "\n",
    "c = np.zeros(1, dtype=int)\n",
    "pAc = 0.9\n",
    "delay_c = 15 #seconds\n",
    "duration_c = 120\n",
    "\n",
    "#Alarm Series Generation, A (cause), B(Effect). C(Effect)\n",
    "while(occor_num < ocorr): \n",
    "    \n",
    "    #A generation - begin\n",
    "    srtd_hour = random.normalvariate(3, 1)\n",
    "    srtd_hour_begin = hour_init + dt.timedelta(hours=srtd_hour)\n",
    "    srtd_hour_end = srtd_hour_begin + dt.timedelta(seconds = duration)\n",
    "\n",
    "    idx_init_a_occor = int(math.ceil((srtd_hour_begin - base_hour).total_seconds()/t_sample))\n",
    "    idx_end_a_occor = int(math.ceil((srtd_hour_end - base_hour).total_seconds()/t_sample))\n",
    "        \n",
    "    if(idx_end_a_occor > a.size):\n",
    "            a.resize(idx_end_a_occor)\n",
    "\n",
    "    for i in np.arange(idx_init_a_occor, idx_end_a_occor + 1):\n",
    "        a[i-1] = 1\n",
    "    #A generation - end\n",
    "         \n",
    "    \n",
    "    #B generation begin\n",
    "    srtd_prob_b = random.uniform(0,1)  \n",
    "    if srtd_prob_b <= pAb:\n",
    "        srtd_hour_begin_b = srtd_hour_begin + dt.timedelta(hours = delay_b/3600)\n",
    "        srtd_hour_end_b = srtd_hour_begin_b + dt.timedelta(seconds=duration_b)\n",
    "\n",
    "        idx_init_b_occor = int(math.ceil((srtd_hour_begin_b - base_hour).total_seconds()/t_sample))\n",
    "        idx_end_b_occor = int(math.ceil((srtd_hour_end_b - base_hour).total_seconds()/t_sample))\n",
    "\n",
    "        if(idx_end_b_occor > b.size):\n",
    "                b.resize(idx_end_b_occor)\n",
    "\n",
    "        for j in np.arange(idx_init_b_occor, idx_end_b_occor +1):\n",
    "            b[j-1] =  1  \n",
    "\n",
    "    #B generation end\n",
    "\n",
    "    #C generation begin\n",
    "    srtd_prob_c = random.uniform(0,1)\n",
    "    if srtd_prob_c <= pAc:\n",
    "        srtd_hour_begin_c = srtd_hour_begin + dt.timedelta(hours = delay_b/3600)\n",
    "        srtd_hour_end_c = srtd_hour_begin_c + dt.timedelta(seconds=duration_c)\n",
    "\n",
    "        idx_init_c_occor = int(math.ceil((srtd_hour_begin_c - base_hour).total_seconds()/t_sample))\n",
    "        idx_end_c_occor = int(math.ceil((srtd_hour_end_c - base_hour).total_seconds()/t_sample))\n",
    "        \n",
    "        if(idx_end_c_occor > c.size):\n",
    "            c.resize(idx_end_c_occor)\n",
    "\n",
    "        for j in np.arange(idx_init_c_occor, idx_end_c_occor +1):\n",
    "            c[j-1] = 1    \n",
    "    #C generation end\n",
    "    \n",
    "    hour_init = srtd_hour_begin\n",
    "    occor_num = occor_num + 1\n",
    "\n",
    "#Making series the same length\n",
    "max_len = max(a, b, c, key=len).size\n",
    "a = np.concatenate([a, np.zeros(max_len - a.size)])\n",
    "b = np.concatenate([b, np.zeros(max_len - b.size)])\n",
    "c = np.concatenate([c, np.zeros(max_len - c.size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_sinte = transferEntropy_case(df_sint, 2,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.00000000e+00, 3.82901724e-02, 4.51371127e-02],\n",
       "        [1.53598801e-03, 0.00000000e+00, 3.45600771e-06],\n",
       "        [2.15000729e-03, 7.54158385e-06, 0.00000000e+00]]),\n",
       " array([[0., 1., 1.],\n",
       "        [1., 0., 1.],\n",
       "        [1., 1., 0.]])]"
      ]
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_sinte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sint = pd.DataFrame(data = np.transpose([a,b,c]), columns=['a','b','c'])\n",
    "df_sint.to_csv(\"resultados_defesa/df_sint.csv\")\n",
    "t = np.mean(te_sinte[0]) + 3*np.std(te_sinte[0])\n",
    "df_sint_te = pd.DataFrame(te_sinte[0], columns = df_sint.columns, index= df_sint.columns)\n",
    "df_sint_lag = pd.DataFrame(te_sinte[1], columns = df_sint.columns, index= df_sint.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sint_te.to_csv(\"resultados_defesa/te_sint.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rute/anaconda3/envs/pesquisa/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"80pt\" height=\"218pt\"\n",
       " viewBox=\"0.00 0.00 79.95 218.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 214)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-214 75.9506,-214 75.9506,4 -4,4\"/>\n",
       "<!-- a -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>a</title>\n",
       "<ellipse fill=\"#c9c9c9\" stroke=\"#c0c0c0\" cx=\"36.9506\" cy=\"-192\" rx=\"12.2254\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"36.9506\" y=\"-189.5\" font-family=\"Times,serif\" font-size=\"10.00\" fill=\"#000000\">a</text>\n",
       "</g>\n",
       "<!-- b -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>b</title>\n",
       "<ellipse fill=\"#c9c9c9\" stroke=\"#c0c0c0\" cx=\"12.9506\" cy=\"-105\" rx=\"12.9014\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"12.9506\" y=\"-102.5\" font-family=\"Times,serif\" font-size=\"10.00\" fill=\"#000000\">b</text>\n",
       "</g>\n",
       "<!-- a&#45;&gt;b -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>a&#45;&gt;b</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M32.3231,-175.2255C28.9253,-162.9082 24.2398,-145.9233 20.3279,-131.7429\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"23.679,-130.729 17.6457,-122.0198 16.9311,-132.5905 23.679,-130.729\"/>\n",
       "<text text-anchor=\"middle\" x=\"35.9506\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1.0</text>\n",
       "</g>\n",
       "<!-- c -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>c</title>\n",
       "<ellipse fill=\"#c9c9c9\" stroke=\"#c0c0c0\" cx=\"36.9506\" cy=\"-18\" rx=\"12.2254\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"36.9506\" y=\"-15.5\" font-family=\"Times,serif\" font-size=\"10.00\" fill=\"#000000\">c</text>\n",
       "</g>\n",
       "<!-- a&#45;&gt;c -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>a&#45;&gt;c</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M42.9174,-176.1062C44.9428,-169.9239 46.9465,-162.7221 47.9506,-156 54.6477,-111.1641 54.6477,-98.8359 47.9506,-54 47.4485,-50.639 46.6966,-47.158 45.817,-43.7445\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"49.0988,-42.4985 42.9174,-33.8938 42.3837,-44.4752 49.0988,-42.4985\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.9506\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1.0</text>\n",
       "</g>\n",
       "<!-- b&#45;&gt;c -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>b&#45;&gt;c</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M17.6922,-87.8116C21.0999,-75.4586 25.7586,-58.571 29.6403,-44.4998\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"33.0151,-45.4274 32.3005,-34.8567 26.2671,-43.5658 33.0151,-45.4274\"/>\n",
       "<text text-anchor=\"middle\" x=\"35.9506\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1.0</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f0371cf7ac8>"
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_graf_ac = generate_aciclic_graph(te_sinte[1])\n",
    "df_sinte_ac = pd.DataFrame(mat_graf_ac,  columns=df_sint_te.columns, index=df_sint_te.columns)\n",
    "df_sinte_ac.to_csv(\"resultados_defesa/sint_ac.csv\")\n",
    "graph_simple(df_sinte_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"98pt\" height=\"131pt\"\n",
       " viewBox=\"0.00 0.00 98.22 131.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 127)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-127 94.2199,-127 94.2199,4 -4,4\"/>\n",
       "<!-- a -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>a</title>\n",
       "<ellipse fill=\"#c9c9c9\" stroke=\"#c0c0c0\" cx=\"36.2693\" cy=\"-105\" rx=\"12.2254\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"36.2693\" y=\"-102.5\" font-family=\"Times,serif\" font-size=\"10.00\" fill=\"#000000\">a</text>\n",
       "</g>\n",
       "<!-- c -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>c</title>\n",
       "<ellipse fill=\"#c9c9c9\" stroke=\"#c0c0c0\" cx=\"14.2693\" cy=\"-18\" rx=\"12.2254\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"14.2693\" y=\"-15.5\" font-family=\"Times,serif\" font-size=\"10.00\" fill=\"#000000\">c</text>\n",
       "</g>\n",
       "<!-- a&#45;&gt;c -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>a&#45;&gt;c</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M25.0664,-96.963C17.029,-90.4563 6.8429,-80.5036 2.2693,-69 -1.1605,-60.3732 .0518,-50.5188 2.75,-41.7869\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"6.1158,-42.7834 6.4109,-32.1927 -.4242,-40.2879 6.1158,-42.7834\"/>\n",
       "<text text-anchor=\"middle\" x=\"11.2693\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1.0</text>\n",
       "</g>\n",
       "<!-- b -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>b</title>\n",
       "<ellipse fill=\"#c9c9c9\" stroke=\"#c0c0c0\" cx=\"77.2693\" cy=\"-18\" rx=\"12.9014\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"77.2693\" y=\"-15.5\" font-family=\"Times,serif\" font-size=\"10.00\" fill=\"#000000\">b</text>\n",
       "</g>\n",
       "<!-- a&#45;&gt;b -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>a&#45;&gt;b</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M43.4109,-89.8458C49.5464,-76.8267 58.5094,-57.8076 65.6725,-42.6079\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"68.9749,-43.8104 70.0719,-33.2725 62.6428,-40.8263 68.9749,-43.8104\"/>\n",
       "<text text-anchor=\"middle\" x=\"67.2693\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1.0</text>\n",
       "</g>\n",
       "<!-- c&#45;&gt;a -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>c&#45;&gt;a</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M18.6067,-35.1527C21.678,-47.2983 25.8611,-63.8404 29.3854,-77.7775\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"26.0779,-78.9748 31.9228,-87.8116 32.8643,-77.2587 26.0779,-78.9748\"/>\n",
       "<text text-anchor=\"middle\" x=\"36.2693\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1.0</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f0371d4ba58>"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_te_vld = generate_df_valid_corrs(df_sint_te, 0.0021500072853693807)\n",
    "\n",
    "df_lag_ltd = (df_sint_lag[df_te_vld > 0]).fillna(0)\n",
    "df_lag_ltd.to_csv('resultados_defesa/sinte_lag_ltd.csv')\n",
    "graph_simple(df_lag_ltd)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "TransEntropy.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
