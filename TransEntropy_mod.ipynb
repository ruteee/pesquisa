{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2BVRzkJYvvww"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime as dt\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "#import statsmodels.api as sm\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from graphviz import Digraph\n",
    "#import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "n1Getoki4DUF",
    "outputId": "fc272523-0489-40ec-deb9-51ae07578b85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in /home/rute/anaconda3/envs/pesquisa/lib/python3.7/site-packages (0.8.4)\n",
      "\u001b[31mmkl-random 1.0.1 requires cython, which is not installed.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# https://pypi.python.org/pypi/pydot\n",
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MENjzHQfvvwz"
   },
   "outputs": [],
   "source": [
    "def get_lim_index(cdf, lim):\n",
    "    summation = 0\n",
    "    index = 0\n",
    "    for i in np.arange(0, cdf.size):\n",
    "        if cdf[i] > lim:\n",
    "            index = i\n",
    "            break\n",
    "    return index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "59-3a3e3vvw1"
   },
   "outputs": [],
   "source": [
    "def surrogate(a):\n",
    "    a_diff = np.diff(a)\n",
    "    begin = np.where(a_diff > 0)[0]\n",
    "    end = np.where(a_diff < 0)[0]\n",
    "    \n",
    "    if begin.size > end.size:\n",
    "        end = np.append(end, a.size)\n",
    "    elif begin.size < end.size:\n",
    "        begin = np.insert(begin, 0, 0) \n",
    "    elif begin.size == 0 and end.size == 0:\n",
    "        return a.copy()\n",
    "    elif np.all(begin > end):\n",
    "        begin = np.insert(begin, 0, 0)\n",
    "        end = np.append(end, a.size)\n",
    "    \n",
    "    n_seq = np.max([begin.size, end.size])\n",
    "    a_surr = np.zeros(a.shape)\n",
    "    p_seq = np.random.randint(0, a.size - max(end - begin), size=n_seq)\n",
    "    for i in np.random.permutation(n_seq):\n",
    "        len_seq = end[i] - begin[i]\n",
    "        a_surr[p_seq[i]:p_seq[i] + len_seq] = a[begin[i]:end[i]]\n",
    "    return a_surr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xITmxUD-vvw3"
   },
   "outputs": [],
   "source": [
    "#Method using stats model kde to return transfer etnropy value limit. That is, the 'x' value corresponding to P95\n",
    "def significance_test(k,l,h,sup_lim, n, a,b):\n",
    "    '''\n",
    "        significance_test(a,b,k,l,h,sup_lim, n)\n",
    "    '''\n",
    "    transferEntropies = []    \n",
    "    \n",
    "    np.random.seed(int(time.time()))\n",
    "    for i in np.arange(0,n):\n",
    "        surrogate_a = surrogate(a.copy())\n",
    "        transferEntropies.append(te(k,l,h,surrogate_a[:],b, 'serie_a', 'serie_b'))\n",
    "        \n",
    "    kde = sm.nonparametric.KDEUnivariate(transferEntropies)\n",
    "    kde.fit()\n",
    "    \n",
    "    \n",
    "    lvl_sig = kde.icdf[get_lim_index(kde.cdf, sup_lim)]\n",
    "    return lvl_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8H540fy4vvw4"
   },
   "outputs": [],
   "source": [
    "##for paper test\n",
    "def joint_probability_new(k,l,h, a, b, lbl_a, lbl_b):\n",
    "    '''\n",
    "        k B time horizon\n",
    "        l A time horizon\n",
    "        h instant in the future of serie B\n",
    "        \n",
    "        \n",
    "        a, b array type'''\n",
    "    \n",
    "    numStates=2**(k+l+1)\n",
    "    combinations = list(map(list, itertools.product([0, 1], repeat=k+l+1)))\n",
    "    prob_cnjt = np.zeros(numStates)\n",
    "    \n",
    "    #Alarm Series A (cause), B (effect), same len\n",
    "    #teste   \n",
    "\n",
    "    matrix_nova = np.matrix([b[1:],b[:-1],a[:-1]]).T\n",
    "    df = pd.DataFrame(matrix_nova, columns = ['b_ftr', lbl_b, lbl_a])\n",
    "    gpd = df.groupby(['b_ftr', lbl_b, lbl_a], as_index=False).size().reset_index(name='Count')\n",
    "    total = sum(gpd['Count'])\n",
    "    \n",
    "    for i in np.arange(0,gpd.shape[0]):\n",
    "        comb = [e for e in gpd.iloc[i][0:3].values.tolist()]\n",
    "        idx = combinations.index(comb)\n",
    "        prob_cnjt[idx] = gpd.iloc[i]['Count']/total\n",
    "\n",
    "    return prob_cnjt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oJ1KZo1Zvvw6"
   },
   "outputs": [],
   "source": [
    "def joint_probability(k,l, h, a, b):\n",
    "    '''\n",
    "        k B time horizon\n",
    "        l A time horizon\n",
    "        h instant in the future of serie B\n",
    "        \n",
    "        a, b array type'''\n",
    "\n",
    "    #Alarm Series A (cause), B (effect), same len\n",
    "    #tested\n",
    "    sizeSeries = a.size\n",
    "    transEntropy = 0\n",
    "    numStates = 2**(k + l  + 1)\n",
    "    combinations = list(map(list, itertools.product([0, 1], repeat=k+l+1)))\n",
    "    counting = np.zeros(numStates)\n",
    "    prob_cnjt = np.zeros(numStates)\n",
    "    a_prob_ind = []\n",
    "    b_prob_ind = []\n",
    "    #joitn probability p(i_sub_t+1), i_sub_t**k, j_sub_t**l)\n",
    "    inicio = np.max([k,l]) - 1\n",
    "    for i in np.arange(inicio, sizeSeries - h):\n",
    "        for hk in np.arange(0,k):\n",
    "                b_prob_ind.append(b[i - hk])\n",
    "        for hl in np.arange(0,l):\n",
    "                a_prob_ind.append(a[i - hl])\n",
    "\n",
    "        #print(a.size, b.size, a.size -1)     \n",
    "        ab = [b[i + h]] + b_prob_ind + a_prob_ind \n",
    "        index_comb = combinations.index(ab)\n",
    "        counting[index_comb] = counting[index_comb] + 1\n",
    "\n",
    "        a_prob_ind = []\n",
    "        b_prob_ind = []\n",
    "\n",
    "    total = sum(counting)\n",
    "  \n",
    "    prob_cnjt = counting/total\n",
    "     \n",
    "    return prob_cnjt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kDxNQD_Hvvw9"
   },
   "outputs": [],
   "source": [
    "#Joint probability evaluation p(i_t+h, i_t**k)\n",
    "#tested\n",
    "def joint_prob_ih_ik(k,l, joint_prob_ih_ik_jl):\n",
    "    states_ith_ik = list(map(list, itertools.product([0, 1], repeat=k + 1)))\n",
    "    combinations = list(map(list, itertools.product([0, 1], repeat=k+l+1))) \n",
    "    p_jnt_ith_ik = np.zeros(2**(k+1))\n",
    "    \n",
    "    for i, state in enumerate(states_ith_ik):\n",
    "        for j, comb in enumerate(combinations):\n",
    "            if comb[0:k+1] == state:\n",
    "                p_jnt_ith_ik[i] = p_jnt_ith_ik[i] + joint_prob_ih_ik_jl[j]\n",
    "    return p_jnt_ith_ik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mqUnJUDcvvw_"
   },
   "outputs": [],
   "source": [
    "def conditional_prob(k,l,joint_prob):\n",
    "    states = list(map(list, itertools.product([0, 1], repeat=k+l)))\n",
    "    combinations = list(map(list, itertools.product([0, 1], repeat=k+l+1)))\n",
    "\n",
    "    size = int(joint_prob.size/2)\n",
    "    conditional = np.zeros(2**(k+l+1))\n",
    "\n",
    "    for i,state in enumerate(states):\n",
    "        index_zero = combinations.index([0] + state)\n",
    "        prob_zero = joint_prob[index_zero]\n",
    "\n",
    "        index_one = combinations.index([1] + state)\n",
    "        prob_one = joint_prob[index_one]\n",
    "\n",
    "        if(prob_zero + prob_one != 0):\n",
    "            conditional[i] = prob_zero/(prob_zero+ prob_one)\n",
    "            conditional[i + 2**(k+l)] = prob_one/(prob_zero+ prob_one)\n",
    "    return conditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MNFelkuVvvxA"
   },
   "outputs": [],
   "source": [
    "#Division of the conditionals in log2 \n",
    "#tested\n",
    "def conditional_div(k,l,conditional_num, conditional_den):\n",
    "    combinations = list(map(list, itertools.product([0, 1], repeat=k+l+1)))\n",
    "    conditional_division = np.zeros(conditional_num.size)\n",
    "    states_den = list(map(list, itertools.product([0, 1], repeat=1+k)))\n",
    "    for j, comb in enumerate(combinations):\n",
    "        if(conditional_den[states_den.index(comb[0:k+1])] != 0):\n",
    "            conditional_division[j] = conditional_num[j]/conditional_den[states_den.index(comb[0:k+1])]            \n",
    "    return conditional_division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dpGL8DlsvvxF"
   },
   "outputs": [],
   "source": [
    "#Transfer entropy final evaluation\n",
    "def te(k,l,h_window, a,b):\n",
    "    '''\n",
    "        transentropy a->b\n",
    "        te(k,l,h,a,b)\n",
    "        k - dimension of b\n",
    "        l - dimension of a\n",
    "        h -> instant in the future of a\n",
    "    '''\n",
    "    #joint_p_ih_ik_jl = joint_probability_new(k,l,h,a,b, lbl_a, lbl_b)\n",
    "    \n",
    "    te_by_h = []\n",
    "    for h in np.arange(1,h_window):\n",
    "      joint_p_ih_ik_jl = joint_probability(k,l,h,a,b)\n",
    "\n",
    "      joint_p_ih_ik = joint_prob_ih_ik(k,l, joint_p_ih_ik_jl)\n",
    "      conditional_num = conditional_prob(k,l,joint_p_ih_ik_jl)\n",
    "      conditional_den = conditional_prob(k,0, joint_p_ih_ik)    \n",
    "      div = conditional_div(k,l,conditional_num, conditional_den)\n",
    "\n",
    "      #log2 from the division of the conditionals -> #p(i_sub_t+h|i_sub_t**k, j_sub_t**l) /p(i_sub_t+h|i_t**k)\n",
    "      log2_div_cond = np.log2(div[div!=0])\n",
    "      te = np.sum(joint_p_ih_ik_jl[div!=0]*log2_div_cond)\n",
    "      \n",
    "      te_by_h.append(te)\n",
    "      lag = np.argmax(te_by_h) + 1\n",
    "    return [max(te_by_h), lag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "phi8XuryvvxI"
   },
   "outputs": [],
   "source": [
    "def transferEntropy_case(dist_df, h, k, l):\n",
    "    #start = time.clock()\n",
    "    transEntropy = np.zeros([dist_df.columns.size,dist_df.columns.size])\n",
    "    lagEntropy = np.zeros([dist_df.columns.size,dist_df.columns.size])\n",
    "    sigValues =  np.zeros([dist_df.columns.size,dist_df.columns.size])\n",
    "    for i in np.arange(0, dist_df.columns.size):\n",
    "        for j in np.arange(0, dist_df.columns.size):\n",
    "            print('trans ', dist_df.columns[i], dist_df.columns[j])\n",
    "            if(j != i + dist_df.columns.size/2 and j!=i and j != i - dist_df.columns.size/2):\n",
    "                te_result = te(k,l,h, dist_df[dist_df.columns[i]], dist_df[dist_df.columns[j]])\n",
    "                transEntropy[i][j] = te_result[0]\n",
    "                lagEntropy[i][j] = te_result[1]\n",
    "                \n",
    "            clear_output()\n",
    "    #end = time.clock()   \n",
    "    \n",
    "    #print(end - start)\n",
    "    return [transEntropy, lagEntropy]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_roll_mean(df, window):\n",
    "    roll  = df.copy().rolling(window).mean() \n",
    "    roll.dropna(inplace=True)\n",
    "    roll = roll.round(decimals=0).copy()\n",
    "    roll.reset_index(drop=True, inplace=True)\n",
    "    return roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_simple(df, eng = 'dot'):\n",
    "    edge_style = \"\"\n",
    "    g = Digraph(engine=eng)\n",
    "   \n",
    "    for k, row in enumerate(df.index):\n",
    "        if any(df.iloc[k]) or any(df[row]):\n",
    "            g.node(str(k),row, shape='oval', fontsize='10', width='0', style='filled', fillcolor='#c9c9c9', color=\"gray\") \n",
    "\n",
    "    for j, col in enumerate(df.columns):\n",
    "        for i, row in enumerate(df[col]):\n",
    "            if(row):\n",
    "                g.edge(str(i), str(j), label='',style= edge_style, color='dark')  \n",
    "    return g "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RR3gnznz4Vx9"
   },
   "outputs": [],
   "source": [
    "def graph(df, df_lag, eng = 'dot'):\n",
    "    edge_style = \"\"\n",
    "    g = Digraph(engine=eng)\n",
    "   \n",
    "    for k, row in enumerate(df.index):\n",
    "        if any(df.iloc[k]) or any(df[row]):\n",
    "            g.node(str(k),row, shape='oval', fontsize='10', width='0', style='filled', fillcolor='#c9c9c9', color=\"gray\") \n",
    "\n",
    "    for j, col in enumerate(df.columns):\n",
    "        for i, row in enumerate(df[col]):\n",
    "            if(row):\n",
    "                te_val  = str(np.round(row, 6))\n",
    "                g.edge(str(i), str(j), label=str(df_lag[df_lag.columns[j]][i]),style= edge_style, color='dark')  \n",
    "    return g "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_from_dict(dictionary, eng = 'dot'):\n",
    "    edge_style = \"\"\n",
    "    g = Digraph(engine=eng)\n",
    "   \n",
    "    for k, i in dictionary.items():\n",
    "        g.node(str(k),k, shape='oval', fontsize='10', width='0', style='filled', fillcolor='#c9c9c9', color=\"gray\") \n",
    "        df_te.m\n",
    "    for k, i in dictionary.items():\n",
    "        for it in i:\n",
    "            g.edge(str(it), str(k), label='',style= edge_style, color='dark')  \n",
    "    return g "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t9nN9piiG0aC"
   },
   "outputs": [],
   "source": [
    "def generate_df_valid_corrs(df, limit):\n",
    "    df_valid = df.copy()\n",
    "    for row in df.columns:\n",
    "        for col in df.columns:\n",
    "            if df[row][col] < limit:\n",
    "                df_valid[row][col] = 0\n",
    "                \n",
    "    return df_valid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_df_max_info(df):\n",
    "    df_max_info = pd.DataFrame(data = np.zeros([len(df),len(df)]),columns=df.columns, index = df.columns)\n",
    "    for  i,col in enumerate(df.columns):\n",
    "        sort = df[col].sort_values(ascending=False)\n",
    "        df_max_info.loc[sort.index[0]][i] = sort[0]\n",
    "    return df_max_info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_first_diff(df):\n",
    "    dist_diff = df.diff()\n",
    "    dist_diff.clip(lower=0, inplace=True)\n",
    "    dist_diff.dropna(inplace=True)\n",
    "    dist_diff.reset_index(drop=True, inplace=True)\n",
    "    dist_diff = dist_diff.astype(int)\n",
    "    \n",
    "    return dist_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_smtc_cicle(df):\n",
    "    rm_df = df.copy()\n",
    "    for c, col in enumerate(rm_df.columns):\n",
    "        for r, row in enumerate(rm_df[col]):\n",
    "            simetric_val = rm_df[rm_df.columns[r]][c]\n",
    "            if row and simetric_val:\n",
    "                if simetric_val >= row:\n",
    "                    rm_df[col][r] = 0\n",
    "                else:\n",
    "                    simetric_val = 0\n",
    "    return rm_df\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dictTree(df):\n",
    "    dict_tree = {}\n",
    "    for col in df.columns:\n",
    "        non_zero = df[col].nonzero()\n",
    "        dict_tree[col] = df[col].index[non_zero].values.tolist()\n",
    "    return dict_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oDS2t1TEzrOX"
   },
   "outputs": [],
   "source": [
    "dist6 = pd.read_csv(\"dist6_3horas_sig/alm_seq.csv\")\n",
    "dist = dist6[['xmeas%02d_low' % x for x in [1,2,3,8,9,21]] + ['xmeas%02d_high' % x for x in [1,2,3,8,9,21]]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying 5 samples mooving mean\n",
    "df_mean5 = apply_roll_mean(dist, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kHKLOOBK0r8_"
   },
   "outputs": [],
   "source": [
    "#computing TE\n",
    "te_matrix = transferEntropy_case(df_mean5, 50, 1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building DF from te matrix\n",
    "t = np.mean(te_matrix[0]) + 3*np.std(te_matrix[0])\n",
    "df_te = pd.DataFrame(te_matrix[0], columns = dist.columns, index= dist.columns)\n",
    "df_te_lag = pd.DataFrame(te_matrix[1], columns = dist.columns, index= dist.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving df te\n",
    "df_te.to_csv('resultados_defesa/te_m5_h50.csv')\n",
    "df_te_lag.to_csv(\"resultados_defesa/te_m5_h50_lag.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xmeas01_low</th>\n",
       "      <th>xmeas02_low</th>\n",
       "      <th>xmeas03_low</th>\n",
       "      <th>xmeas08_low</th>\n",
       "      <th>xmeas09_low</th>\n",
       "      <th>xmeas21_low</th>\n",
       "      <th>xmeas01_high</th>\n",
       "      <th>xmeas02_high</th>\n",
       "      <th>xmeas03_high</th>\n",
       "      <th>xmeas08_high</th>\n",
       "      <th>xmeas09_high</th>\n",
       "      <th>xmeas21_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>xmeas01_low</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.152564</td>\n",
       "      <td>0.082146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xmeas02_low</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xmeas03_low</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xmeas08_low</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xmeas09_low</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xmeas21_low</th>\n",
       "      <td>0.055675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031919</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xmeas01_high</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018317</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xmeas02_high</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xmeas03_high</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xmeas08_high</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xmeas09_high</th>\n",
       "      <td>0.018163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072729</td>\n",
       "      <td>0.098622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xmeas21_high</th>\n",
       "      <td>0.075712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.398793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124627</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              xmeas01_low  xmeas02_low  xmeas03_low  xmeas08_low  xmeas09_low  \\\n",
       "xmeas01_low      0.000000          0.0          0.0          0.0          0.0   \n",
       "xmeas02_low      0.000000          0.0          0.0          0.0          0.0   \n",
       "xmeas03_low      0.000000          0.0          0.0          0.0          0.0   \n",
       "xmeas08_low      0.000000          0.0          0.0          0.0          0.0   \n",
       "xmeas09_low      0.000000          0.0          0.0          0.0          0.0   \n",
       "xmeas21_low      0.055675          0.0          0.0          0.0          0.0   \n",
       "xmeas01_high     0.000000          0.0          0.0          0.0          0.0   \n",
       "xmeas02_high     0.000000          0.0          0.0          0.0          0.0   \n",
       "xmeas03_high     0.000000          0.0          0.0          0.0          0.0   \n",
       "xmeas08_high     0.000000          0.0          0.0          0.0          0.0   \n",
       "xmeas09_high     0.018163          0.0          0.0          0.0          0.0   \n",
       "xmeas21_high     0.075712          0.0          0.0          0.0          0.0   \n",
       "\n",
       "              xmeas21_low  xmeas01_high  xmeas02_high  xmeas03_high  \\\n",
       "xmeas01_low      0.136187      0.000000           0.0           0.0   \n",
       "xmeas02_low      0.000000      0.000000           0.0           0.0   \n",
       "xmeas03_low      0.000000      0.000000           0.0           0.0   \n",
       "xmeas08_low      0.000000      0.000000           0.0           0.0   \n",
       "xmeas09_low      0.000000      0.000000           0.0           0.0   \n",
       "xmeas21_low      0.000000      0.133873           0.0           0.0   \n",
       "xmeas01_high     0.076599      0.000000           0.0           0.0   \n",
       "xmeas02_high     0.000000      0.000000           0.0           0.0   \n",
       "xmeas03_high     0.000000      0.000000           0.0           0.0   \n",
       "xmeas08_high     0.000000      0.000000           0.0           0.0   \n",
       "xmeas09_high     0.072729      0.098622           0.0           0.0   \n",
       "xmeas21_high     0.000000      0.398793           0.0           0.0   \n",
       "\n",
       "              xmeas08_high  xmeas09_high  xmeas21_high  \n",
       "xmeas01_low            0.0      0.152564      0.082146  \n",
       "xmeas02_low            0.0      0.000000      0.000000  \n",
       "xmeas03_low            0.0      0.000000      0.000000  \n",
       "xmeas08_low            0.0      0.000000      0.000000  \n",
       "xmeas09_low            0.0      0.000000      0.020371  \n",
       "xmeas21_low            0.0      0.031919      0.000000  \n",
       "xmeas01_high           0.0      0.018317      0.000000  \n",
       "xmeas02_high           0.0      0.000000      0.000000  \n",
       "xmeas03_high           0.0      0.000000      0.000000  \n",
       "xmeas08_high           0.0      0.000000      0.000000  \n",
       "xmeas09_high           0.0      0.000000      0.022588  \n",
       "xmeas21_high           0.0      0.124627      0.000000  "
      ]
     },
     "execution_count": 1507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_roc = 0.01816308533330481\n",
    "t_roc2 = 0.055674922579944816\n",
    "df_ltd = generate_df_valid_corrs(df_te, t_roc)\n",
    "df_ltd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1261,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ltd.to_csv(\"resultados_defesa/df_te_50_ltd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph(df_te, df_te_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1269,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph(df_ltd, df_te_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ancestrals(lista, node, lista_nova):\n",
    "    if np.all(np.unique(lista[node]) == ['x']):\n",
    "        return lista_nova\n",
    "    \n",
    "    if not node in lista_nova:\n",
    "        lista_nova.extend([node])\n",
    "            \n",
    "    if not lista[node]:\n",
    "        return lista_nova\n",
    "    else:\n",
    "        for i,no in enumerate(lista[node]):       \n",
    "            idx = no\n",
    "            node_to_list = [lista[node][i]]\n",
    "            lista[node][i] = 'x'\n",
    "            if no == 'x':\n",
    "                continue\n",
    "            if 'x' in lista[no]:\n",
    "                get_ancestrals(lista, idx, lista_nova)   \n",
    "            elif not lista[no]:\n",
    "                lista_nova.extend(node_to_list)\n",
    "                lista[no] = ['x']\n",
    "                continue\n",
    "            else:\n",
    "                lista_nova.extend(node_to_list)\n",
    "                get_ancestrals(lista, idx, lista_nova)             \n",
    "        else:\n",
    "            return get_ancestrals(lista, node, lista_nova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_aciclic_graph(grafo_param):\n",
    "    graph_mat = copy.deepcopy(grafo_param)\n",
    "    grafo_ac = np.zeros([len(graph_mat), len(graph_mat)], dtype=float)\n",
    "    ancestrals = [[] for el in np.arange(0, len(graph_mat))]\n",
    "    \n",
    "    max_val = max(graph_mat.flatten().tolist())\n",
    "    idx_max = np.argmax(graph_mat.flatten().tolist())  \n",
    "\n",
    "    while(max_val > 0):\n",
    "        idx_row = int(np.floor(idx_max)/len(graph_mat))\n",
    "        idx_col = idx_max - len(graph_mat)*idx_row\n",
    "\n",
    "        impossible_nodes = []\n",
    "        if ancestrals[idx_row]:\n",
    "            impossible_nodes = get_ancestrals(copy.deepcopy(ancestrals),idx_row, [])\n",
    "            if not idx_col in impossible_nodes:\n",
    "                grafo_ac[idx_row, idx_col] = graph_mat[idx_row, idx_col]\n",
    "                ancestrals[idx_col] += [idx_row] \n",
    "        else:\n",
    "            ancestrals[idx_col] += [idx_row]\n",
    "            grafo_ac[idx_row,idx_col] = max_val\n",
    "\n",
    "        graph_mat[idx_row, idx_col] = 0\n",
    "        max_val = max(graph_mat.flatten().tolist())\n",
    "        idx_max = np.argmax(graph_mat.flatten())\n",
    "    return grafo_ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_aciclic_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-40fe26dc37fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgrafo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnovo_grafo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_aciclic_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mte_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_aciclic_graph' is not defined"
     ]
    }
   ],
   "source": [
    "grafo = np.array([[0,5,0,0], [0,0,3,2], [0,1,0,0], [0,0,2,0]])\n",
    "novo_grafo = generate_aciclic_graph(te_matrix[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'novo_grafo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-edd4532ecf6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_graph_ac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnovo_grafo\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_te\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_te\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_graph_ac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resultados_defesa/grafo_ac.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgraph_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_graph_ac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'novo_grafo' is not defined"
     ]
    }
   ],
   "source": [
    "df_graph_ac = pd.DataFrame(novo_grafo,  columns=df_te.columns, index=df_te.columns)\n",
    "df_graph_ac.to_csv(\"resultados_defesa/grafo_ac.csv\")\n",
    "graph_simple(df_graph_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rute/anaconda3/envs/pesquisa/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"229pt\" height=\"392pt\"\n",
       " viewBox=\"0.00 0.00 228.89 392.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 388)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-388 224.8881,-388 224.8881,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"#c9c9c9\" stroke=\"#c0c0c0\" cx=\"87.5611\" cy=\"-366\" rx=\"43.6222\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"87.5611\" y=\"-363.5\" font-family=\"Times,serif\" font-size=\"10.00\" fill=\"#000000\">xmeas01_low</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>5</title>\n",
       "<ellipse fill=\"#c9c9c9\" stroke=\"#c0c0c0\" cx=\"43.5611\" cy=\"-105\" rx=\"43.6222\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"43.5611\" y=\"-102.5\" font-family=\"Times,serif\" font-size=\"10.00\" fill=\"#000000\">xmeas21_low</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;5 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M83.0814,-347.8614C76.0724,-318.8916 62.4962,-260.3142 54.5611,-210 50.5004,-184.2525 47.5567,-154.7088 45.7421,-133.5321\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"49.2071,-132.9632 44.8961,-123.2851 42.2308,-133.5392 49.2071,-132.9632\"/>\n",
       "<text text-anchor=\"middle\" x=\"73.0611\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">41.0</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>10</title>\n",
       "<ellipse fill=\"#c9c9c9\" stroke=\"#c0c0c0\" cx=\"108.5611\" cy=\"-192\" rx=\"45.1548\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"108.5611\" y=\"-189.5\" font-family=\"Times,serif\" font-size=\"10.00\" fill=\"#000000\">xmeas09_high</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;10 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>0&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M88.6445,-347.7386C90.0013,-326.7517 92.6351,-291.3011 96.5611,-261 98.3187,-247.4345 100.8489,-232.4666 103.1333,-219.9486\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"106.5784,-220.5667 104.972,-210.0943 99.6971,-219.2827 106.5784,-220.5667\"/>\n",
       "<text text-anchor=\"middle\" x=\"109.0611\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">49.0</text>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>11</title>\n",
       "<ellipse fill=\"#c9c9c9\" stroke=\"#c0c0c0\" cx=\"175.5611\" cy=\"-279\" rx=\"45.1548\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"175.5611\" y=\"-276.5\" font-family=\"Times,serif\" font-size=\"10.00\" fill=\"#000000\">xmeas21_high</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;11 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>0&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M104.5283,-349.2255C117.7981,-336.1066 136.4235,-317.6928 151.2731,-303.012\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"153.9952,-305.2425 158.6459,-295.723 149.0738,-300.2646 153.9952,-305.2425\"/>\n",
       "<text text-anchor=\"middle\" x=\"145.5611\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">5.0</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>6</title>\n",
       "<ellipse fill=\"#c9c9c9\" stroke=\"#c0c0c0\" cx=\"123.5611\" cy=\"-18\" rx=\"45.1548\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"123.5611\" y=\"-15.5\" font-family=\"Times,serif\" font-size=\"10.00\" fill=\"#000000\">xmeas01_high</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M56.617,-87.4706C64.3857,-77.3775 74.6357,-64.6275 84.5611,-54 88.4133,-49.8753 92.6547,-45.6635 96.8786,-41.6424\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"99.4358,-44.0438 104.3746,-34.6705 94.6685,-38.9181 99.4358,-44.0438\"/>\n",
       "<text text-anchor=\"middle\" x=\"97.0611\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">28.0</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;5 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>10&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M95.4073,-174.3943C86.007,-161.8122 73.2115,-144.6859 62.6843,-130.5957\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"65.2626,-128.1989 56.4734,-122.2827 59.6548,-132.3886 65.2626,-128.1989\"/>\n",
       "<text text-anchor=\"middle\" x=\"93.0611\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">18.0</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;6 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>10&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M110.138,-173.7078C112.7556,-143.3436 118.016,-82.3226 121.1174,-46.3464\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"124.6334,-46.3108 122.0053,-36.0471 117.6592,-45.7095 124.6334,-46.3108\"/>\n",
       "<text text-anchor=\"middle\" x=\"129.0611\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">47.0</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;6 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>11&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M173.888,-260.7656C170.4745,-226.3749 161.6379,-149.7498 145.5611,-87 142.0504,-73.2976 137.3767,-58.3131 133.2401,-45.8195\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"136.4391,-44.3524 129.929,-35.9937 129.8056,-46.5878 136.4391,-44.3524\"/>\n",
       "<text text-anchor=\"middle\" x=\"172.0611\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">46.0</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;10 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>11&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M158.888,-261.8967C153.4796,-256.069 147.5834,-249.4052 142.5611,-243 136.4853,-235.2514 130.3598,-226.4413 125.0142,-218.3494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"127.9358,-216.4219 119.559,-209.9349 122.0621,-220.2298 127.9358,-216.4219\"/>\n",
       "<text text-anchor=\"middle\" x=\"155.0611\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">19.0</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f5f5417dda0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_te = pd.read_csv('resultados_defesa/te_m5_h50.csv', index_col=0)\n",
    "df_te_lag = pd.read_csv(\"resultados_defesa/te_m5_h50_lag.csv\", index_col=0)\n",
    "\n",
    "\n",
    "df_ltd = pd.read_csv(\"resultados_defesa/df_te_50_ltd.csv\", index_col=0)\n",
    "grafo_ltd_ac = generate_aciclic_graph(df_ltd.values)\n",
    "df_graph_ltd_ac = pd.DataFrame(grafo_ltd_ac,  columns=df_te.columns, index=df_te.columns)\n",
    "graph(df_graph_ltd_ac, df_te_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lags_final  = df_te_lag[df_graph_ltd_ac > 0].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rute/anaconda3/envs/pesquisa/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[10, 9, 3]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[0,0,0,0,0], [10,0,0,4,2], [2,0,0,0,0],[0,0,3,0,0], [1,0,0,0,0]]\n",
    "lista_nova = []\n",
    "get_lags_parent(a, 1, lista_nova, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['xmeas21_low', 'xmeas09_high', 'xmeas21_high'], dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lags_final.columns[df_lags_final.loc['xmeas01_low'] >0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lags_parent(adj_list, node, lista_nova, id_call):\n",
    "    if np.all(np.unique(adj_list[node]) == 0):\n",
    "        adj_list[node] = ['x' for x in adj_list[node]]\n",
    "        return 0  \n",
    "    soma = 0\n",
    "    for idx, no in enumerate(adj_list[node]):\n",
    "        if no == 'x':\n",
    "            continue\n",
    "        elif no != 0:\n",
    "            soma= no\n",
    "            soma += get_lags_parent(adj_list, idx, lista_nova, id_call+1)\n",
    "            adj_list[node][idx] = 'x'\n",
    "\n",
    "            if id_call==0:\n",
    "                lista_nova.append(soma)\n",
    "        else:\n",
    "            adj_list[node][idx] = 'x' \n",
    "    if id_call == 0:\n",
    "        return lista_nova\n",
    "    return soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parents_tree(df):\n",
    "    parents_from_df = dict()\n",
    "    for i, node in enumerate(df.columns):\n",
    "        parents_from_df[node] = df.columns[df[node] > 0].values\n",
    "    return parents_from_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[0,0,0,0,0], [2,0,0,0,0], [5,0,0,0,3], [0,3,7,0,0],[0,0,0,2,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['x', 'x', 'x', 'x', 'x'],\n",
       " ['x', 'x', 'x', 'x', 'x'],\n",
       " ['x', 'x', 'x', 'x', 'x'],\n",
       " ['x', 'x', 'x', 'x', 'x'],\n",
       " ['x', 'x', 'x', 'x', 'x']]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rute/anaconda3/envs/pesquisa/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lags_parent(data_t, , [], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shift(df_lag, node_start, node_end, lista_nova, id_call, found_end):\n",
    "    if id_call == 0:\n",
    "        adj_df = df_lag.copy()\n",
    "    else:\n",
    "        adj_df = df_lag\n",
    "        \n",
    "    adj_df = df_lag.copy()\n",
    "    if node_start == node_end:\n",
    "        return 0\n",
    "    if np.all(adj_df.loc[node_start].unique() == 0):\n",
    "        adj_df.loc[node_start] = [-1 for x in adj_df.loc[node_start]]\n",
    "        return -1\n",
    "    soma = 0\n",
    "    soma_temp = 0\n",
    "    for idx, no in enumerate(adj_df.loc[node_start]):\n",
    "        if no == -1:\n",
    "            continue\n",
    "        elif no != 0:\n",
    "            soma_temp = get_shift(adj_df, adj_df.columns[idx], node_end, lista_nova, id_call+1, found_end)\n",
    "            if soma_temp != -1:\n",
    "                soma = no\n",
    "                soma += soma_temp\n",
    "            else:\n",
    "                found_end.append(False)\n",
    "            adj_df.at[node_start,adj_df.columns[idx]] = -1\n",
    "            \n",
    "            if id_call == 0:\n",
    "                if np.all(found_end):\n",
    "                    lista_nova.append(('node ' + (node_end)+ '_shift',soma))                \n",
    "        else:\n",
    "            adj_df.at[node_start,adj_df.columns[idx]] = -1\n",
    "    if id_call == 0:\n",
    "        return lista_nova\n",
    "    return soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 2, 5, 0, 0],\n",
       " [0, 0, 0, 3, 0],\n",
       " [0, 0, 0, 0, 7],\n",
       " [0, 0, 0, 0, 2],\n",
       " [0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_t = [[0,2,5,0,0],[0,0,0,3,0],[0,0,0,0,7],[0,0,0,0,2],[0,0,0,0,0]]\n",
    "data_texamp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[0,0,0,0,0,0], [2,0,0,0,0,0], [5,0,0,0,0,2], [0,3,0,0,0,0],[0,0,7,2,0,0],[0,0,0,0,0,0]]\n",
    "examp_df = pd.DataFrame(columns = ['a', 'b', 'c', 'd', 'e','f'], index=['a', 'b', 'c', 'd', 'e', 'f'], data=np.transpose(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['a'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "if np.any(examp_df[examp_df.columns[1]]  > 0):\n",
    "    print(examp_df.columns[examp_df[examp_df.columns[1]]  > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('node e_shift', 7), ('node e_shift', 12)]"
      ]
     },
     "execution_count": 777,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_shift(examp_df, 'a','e',[],0,[])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "TransEntropy.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
