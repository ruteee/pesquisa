{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2BVRzkJYvvww"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime as dt\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "#import statsmodels.api as sm\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from graphviz import Digraph\n",
    "from scipy.ndimage import shift\n",
    "#import pydot\n",
    "\n",
    "\n",
    "from getpass import getpass\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikit_alarm_framework.alarm_generator import set_point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GITHUB_AUTH'] = getpass('GitHub user') + ':' + getpass('GitHub password')\n",
    "\n",
    "!pip -q install -e git+https://${GITHUB_AUTH}@github.com/abugim/scikit-alarm-framework.git@develop#egg=scikit-alarm-framework\n",
    "\n",
    "os.environ.pop('GITHUB_AUTH')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "n1Getoki4DUF",
    "outputId": "fc272523-0489-40ec-deb9-51ae07578b85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in /home/rute/anaconda3/lib/python3.7/site-packages (0.10.1)\r\n"
     ]
    }
   ],
   "source": [
    "# https://pypi.python.org/pypi/pydot\n",
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /home/rute/anaconda3/lib/python3.7/site-packages (19.3.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MENjzHQfvvwz"
   },
   "outputs": [],
   "source": [
    "def get_lim_index(cdf, lim):\n",
    "    summation = 0\n",
    "    index = 0\n",
    "    for i in np.arange(0, cdf.size):\n",
    "        if cdf[i] > lim:\n",
    "            index = i\n",
    "            break\n",
    "    return index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "59-3a3e3vvw1"
   },
   "outputs": [],
   "source": [
    "def surrogate(a):\n",
    "    a_diff = np.diff(a)\n",
    "    begin = np.where(a_diff > 0)[0]\n",
    "    end = np.where(a_diff < 0)[0]\n",
    "    \n",
    "    if begin.size > end.size:\n",
    "        end = np.append(end, a.size)\n",
    "    elif begin.size < end.size:\n",
    "        begin = np.insert(begin, 0, 0) \n",
    "    elif begin.size == 0 and end.size == 0:\n",
    "        return a.copy()\n",
    "    elif np.all(begin > end):\n",
    "        begin = np.insert(begin, 0, 0)\n",
    "        end = np.append(end, a.size)\n",
    "    \n",
    "    n_seq = np.max([begin.size, end.size])\n",
    "    a_surr = np.zeros(a.shape)\n",
    "    p_seq = np.random.randint(0, a.size - max(end - begin), size=n_seq)\n",
    "    for i in np.random.permutation(n_seq):\n",
    "        len_seq = end[i] - begin[i]\n",
    "        a_surr[p_seq[i]:p_seq[i] + len_seq] = a[begin[i]:end[i]]\n",
    "    return a_surr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xITmxUD-vvw3"
   },
   "outputs": [],
   "source": [
    "#Method using stats model kde to return transfer etnropy value limit. That is, the 'x' value corresponding to P95\n",
    "def significance_test(k,l,h,sup_lim, n, a,b):\n",
    "    '''\n",
    "        significance_test(a,b,k,l,h,sup_lim, n)\n",
    "    '''\n",
    "    transferEntropies = []    \n",
    "    \n",
    "    np.random.seed(int(time.time()))\n",
    "    for i in np.arange(0,n):\n",
    "        surrogate_a = surrogate(a.copy())\n",
    "        transferEntropies.append(te(k,l,h,surrogate_a[:],b, 'serie_a', 'serie_b'))\n",
    "        \n",
    "    kde = sm.nonparametric.KDEUnivariate(transferEntropies)\n",
    "    kde.fit()\n",
    "    \n",
    "    \n",
    "    lvl_sig = kde.icdf[get_lim_index(kde.cdf, sup_lim)]\n",
    "    return lvl_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8H540fy4vvw4"
   },
   "outputs": [],
   "source": [
    "##for paper test\n",
    "def joint_probability_new(k,l,h, a, b, lbl_a, lbl_b):\n",
    "    '''\n",
    "        k B time horizon\n",
    "        l A time horizon\n",
    "        h instant in the future of serie B\n",
    "        \n",
    "        \n",
    "        a, b array type'''\n",
    "    \n",
    "    numStates=2**(k+l+1)\n",
    "    combinations = list(map(list, itertools.product([0, 1], repeat=k+l+1)))\n",
    "    prob_cnjt = np.zeros(numStates)\n",
    "    \n",
    "    #Alarm Series A (cause), B (effect), same len\n",
    "    #teste   \n",
    "\n",
    "    matrix_nova = np.matrix([b[1:],b[:-1],a[:-1]]).T\n",
    "    df = pd.DataFrame(matrix_nova, columns = ['b_ftr', lbl_b, lbl_a])\n",
    "    gpd = df.groupby(['b_ftr', lbl_b, lbl_a], as_index=False).size().reset_index(name='Count')\n",
    "    total = sum(gpd['Count'])\n",
    "    \n",
    "    for i in np.arange(0,gpd.shape[0]):\n",
    "        comb = [e for e in gpd.iloc[i][0:3].values.tolist()]\n",
    "        idx = combinations.index(comb)\n",
    "        prob_cnjt[idx] = gpd.iloc[i]['Count']/total\n",
    "\n",
    "    return prob_cnjt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oJ1KZo1Zvvw6"
   },
   "outputs": [],
   "source": [
    "def joint_probability(k,l, h, a, b):\n",
    "    '''\n",
    "        k B time horizon\n",
    "        l A time horizon\n",
    "        h instant in the future of serie B\n",
    "        \n",
    "        a, b array type'''\n",
    "\n",
    "    #Alarm Series A (cause), B (effect), same len\n",
    "    #tested\n",
    "    sizeSeries = a.size\n",
    "    transEntropy = 0\n",
    "    numStates = 2**(k + l  + 1)\n",
    "    combinations = list(map(list, itertools.product([0, 1], repeat=k+l+1)))\n",
    "    counting = np.zeros(numStates)\n",
    "    prob_cnjt = np.zeros(numStates)\n",
    "    a_prob_ind = []\n",
    "    b_prob_ind = []\n",
    "    #joitn probability p(i_sub_t+1), i_sub_t**k, j_sub_t**l)\n",
    "    inicio = np.max([k,l]) - 1\n",
    "    for i in np.arange(inicio, sizeSeries - h):\n",
    "        for hk in np.arange(0,k):\n",
    "                b_prob_ind.append(b[i - hk])\n",
    "        for hl in np.arange(0,l):\n",
    "                a_prob_ind.append(a[i - hl])\n",
    "\n",
    "        #print(a.size, b.size, a.size -1)     \n",
    "        ab = [b[i + h]] + b_prob_ind + a_prob_ind \n",
    "        index_comb = combinations.index(ab)\n",
    "        counting[index_comb] = counting[index_comb] + 1\n",
    "\n",
    "        a_prob_ind = []\n",
    "        b_prob_ind = []\n",
    "\n",
    "    total = sum(counting)\n",
    "  \n",
    "    prob_cnjt = counting/total\n",
    "     \n",
    "    return prob_cnjt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kDxNQD_Hvvw9"
   },
   "outputs": [],
   "source": [
    "#Joint probability evaluation p(i_t+h, i_t**k)\n",
    "#tested\n",
    "def joint_prob_ih_ik(k,l, joint_prob_ih_ik_jl):\n",
    "    states_ith_ik = list(map(list, itertools.product([0, 1], repeat=k + 1)))\n",
    "    combinations = list(map(list, itertools.product([0, 1], repeat=k+l+1))) \n",
    "    p_jnt_ith_ik = np.zeros(2**(k+1))\n",
    "    \n",
    "    for i, state in enumerate(states_ith_ik):\n",
    "        for j, comb in enumerate(combinations):\n",
    "            if comb[0:k+1] == state:\n",
    "                p_jnt_ith_ik[i] = p_jnt_ith_ik[i] + joint_prob_ih_ik_jl[j]\n",
    "    return p_jnt_ith_ik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mqUnJUDcvvw_"
   },
   "outputs": [],
   "source": [
    "def conditional_prob(k,l,joint_prob):\n",
    "    states = list(map(list, itertools.product([0, 1], repeat=k+l)))\n",
    "    combinations = list(map(list, itertools.product([0, 1], repeat=k+l+1)))\n",
    "\n",
    "    size = int(joint_prob.size/2)\n",
    "    conditional = np.zeros(2**(k+l+1))\n",
    "\n",
    "    for i,state in enumerate(states):\n",
    "        index_zero = combinations.index([0] + state)\n",
    "        prob_zero = joint_prob[index_zero]\n",
    "\n",
    "        index_one = combinations.index([1] + state)\n",
    "        prob_one = joint_prob[index_one]\n",
    "\n",
    "        if(prob_zero + prob_one != 0):\n",
    "            conditional[i] = prob_zero/(prob_zero+ prob_one)\n",
    "            conditional[i + 2**(k+l)] = prob_one/(prob_zero+ prob_one)\n",
    "    return conditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MNFelkuVvvxA"
   },
   "outputs": [],
   "source": [
    "#Division of the conditionals in log2 \n",
    "#tested\n",
    "def conditional_div(k,l,conditional_num, conditional_den):\n",
    "    combinations = list(map(list, itertools.product([0, 1], repeat=k+l+1)))\n",
    "    conditional_division = np.zeros(conditional_num.size)\n",
    "    states_den = list(map(list, itertools.product([0, 1], repeat=1+k)))\n",
    "    for j, comb in enumerate(combinations):\n",
    "        if(conditional_den[states_den.index(comb[0:k+1])] != 0):\n",
    "            conditional_division[j] = conditional_num[j]/conditional_den[states_den.index(comb[0:k+1])]            \n",
    "    return conditional_division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dpGL8DlsvvxF"
   },
   "outputs": [],
   "source": [
    "#Transfer entropy final evaluation\n",
    "def te(k,l,h_window, a,b):\n",
    "    '''\n",
    "        transentropy a->b\n",
    "        te(k,l,h,a,b)\n",
    "        k - dimension of b\n",
    "        l - dimension of a\n",
    "        h -> instant in the future of a\n",
    "    '''\n",
    "    #joint_p_ih_ik_jl = joint_probability_new(k,l,h,a,b, lbl_a, lbl_b)\n",
    "    \n",
    "    te_by_h = []\n",
    "    for h in np.arange(1,h_window):\n",
    "      joint_p_ih_ik_jl = joint_probability(k,l,h,a,b)\n",
    "\n",
    "      joint_p_ih_ik = joint_prob_ih_ik(k,l, joint_p_ih_ik_jl)\n",
    "      conditional_num = conditional_prob(k,l,joint_p_ih_ik_jl)\n",
    "      conditional_den = conditional_prob(k,0, joint_p_ih_ik)    \n",
    "      div = conditional_div(k,l,conditional_num, conditional_den)\n",
    "\n",
    "      #log2 from the division of the conditionals -> #p(i_sub_t+h|i_sub_t**k, j_sub_t**l) /p(i_sub_t+h|i_t**k)\n",
    "      log2_div_cond = np.log2(div[div!=0])\n",
    "      te = np.sum(joint_p_ih_ik_jl[div!=0]*log2_div_cond)\n",
    "      \n",
    "      te_by_h.append(te)\n",
    "      lag = np.argmax(te_by_h) + 1\n",
    "    return [max(te_by_h), lag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "phi8XuryvvxI"
   },
   "outputs": [],
   "source": [
    "def transferEntropy_case(dist_df, h, k, l):\n",
    "    #start = time.clock()\n",
    "    transEntropy = np.zeros([dist_df.columns.size,dist_df.columns.size])\n",
    "    lagEntropy = np.zeros([dist_df.columns.size,dist_df.columns.size])\n",
    "    sigValues =  np.zeros([dist_df.columns.size,dist_df.columns.size])\n",
    "    for i in np.arange(0, dist_df.columns.size):\n",
    "        for j in np.arange(0, dist_df.columns.size):\n",
    "            print('trans ', dist_df.columns[i], dist_df.columns[j])\n",
    "            if(j != i + dist_df.columns.size/2 and j!=i and j != i - dist_df.columns.size/2):\n",
    "                te_result = te(k,l,h, dist_df[dist_df.columns[i]], dist_df[dist_df.columns[j]])\n",
    "                transEntropy[i][j] = te_result[0]\n",
    "                lagEntropy[i][j] = te_result[1]\n",
    "                \n",
    "            clear_output()\n",
    "    #end = time.clock()   \n",
    "    \n",
    "    #print(end - start)\n",
    "    return [transEntropy, lagEntropy]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_roll_mean(df, window):\n",
    "    roll  = df.copy().rolling(window).mean() \n",
    "    roll.dropna(inplace=True)\n",
    "    roll = roll.round(decimals=0).copy()\n",
    "    roll.reset_index(drop=True, inplace=True)\n",
    "    return roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_simple(df, eng = 'dot'):\n",
    "    edge_style = \"\"\n",
    "    g = Digraph(engine=eng)\n",
    "    in_graph = []\n",
    "    for k, row in enumerate(df.index):\n",
    "        if any(df.loc[row]):\n",
    "            g.node(str(row),row, shape='oval', fontsize='10', width='0', style='filled', fillcolor='#c9c9c9', color=\"gray\")\n",
    "            in_graph.append(row)\n",
    "\n",
    "              \n",
    "    for c, col in enumerate(df.columns):\n",
    "        if any(df[col]):\n",
    "            if col not in in_graph:\n",
    "                g.node(str(col), col, shape='oval', fontsize='10', width='0', style='filled', fillcolor='#c9c9c9', color=\"gray\") \n",
    "\n",
    "    for j, col in enumerate(df.columns):\n",
    "        for i, row in enumerate(df.index):\n",
    "            if(df[col][i]):\n",
    "                g.edge(str(row), str(col), label=str(df.at[row,col]), style= edge_style, color='black')  \n",
    "    return g "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RR3gnznz4Vx9"
   },
   "outputs": [],
   "source": [
    "def graph(df, df_lag, eng = 'dot'):\n",
    "    edge_style = \"\"\n",
    "    g = Digraph(engine=eng)\n",
    "   \n",
    "    for k, row in enumerate(df.index):\n",
    "        if any(df.iloc[k]) or any(df[row]):\n",
    "            g.node(str(k),row, shape='oval', fontsize='10', width='0', style='filled', fillcolor='#c9c9c9', color=\"gray\") \n",
    "\n",
    "    for j, col in enumerate(df.columns):\n",
    "        for i, row in enumerate(df[col]):\n",
    "            if(row):\n",
    "                te_val  = str(np.round(row, 6))\n",
    "                g.edge(str(i), str(j), label=str(df_lag[df_lag.columns[j]][i]),style= edge_style, color='dark')  \n",
    "    return g "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_from_dict(dictionary, eng = 'dot'):\n",
    "    edge_style = \"\"\n",
    "    g = Digraph(engine=eng)\n",
    "   \n",
    "    for k, i in dictionary.items():\n",
    "        g.node(str(k),k, shape='oval', fontsize='10', width='0', style='filled', fillcolor='#c9c9c9', color=\"gray\") \n",
    "        df_te.m\n",
    "    for k, i in dictionary.items():\n",
    "        for it in i:\n",
    "            g.edge(str(it), str(k), label='',style= edge_style, color='dark')  \n",
    "    return g "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t9nN9piiG0aC"
   },
   "outputs": [],
   "source": [
    "def generate_df_valid_corrs(df, limit):\n",
    "    df_valid = df.copy()\n",
    "    for row in df.columns:\n",
    "        for col in df.columns:\n",
    "            if df[row][col] < limit:\n",
    "                df_valid[row][col] = 0\n",
    "                \n",
    "    return df_valid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_df_max_info(df):\n",
    "    df_max_info = pd.DataFrame(data = np.zeros([len(df),len(df)]),columns=df.columns, index = df.columns)\n",
    "    for  i,col in enumerate(df.columns):\n",
    "        sort = df[col].sort_values(ascending=False)\n",
    "        df_max_info.loc[sort.index[0]][i] = sort[0]\n",
    "    return df_max_info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_first_diff(df):\n",
    "    dist_diff = df.diff()\n",
    "    dist_diff.clip(lower=0, inplace=True)\n",
    "    dist_diff.dropna(inplace=True)\n",
    "    dist_diff.reset_index(drop=True, inplace=True)\n",
    "    dist_diff = dist_diff.astype(int)\n",
    "    \n",
    "    return dist_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_smtc_cicle(df):\n",
    "    rm_df = df.copy()\n",
    "    for c, col in enumerate(rm_df.columns):\n",
    "        for r, row in enumerate(rm_df[col]):\n",
    "            simetric_val = rm_df[rm_df.columns[r]][c]\n",
    "            if row and simetric_val:\n",
    "                if simetric_val >= row:\n",
    "                    rm_df[col][r] = 0\n",
    "                else:\n",
    "                    simetric_val = 0\n",
    "    return rm_df\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ancestrals(lista, node, lista_nova):\n",
    "    if np.all(np.unique(lista[node]) == ['x']):\n",
    "        return lista_nova\n",
    "    \n",
    "    if not node in lista_nova:\n",
    "        lista_nova.extend([node])\n",
    "            \n",
    "    if not lista[node]:\n",
    "        return lista_nova\n",
    "    else:\n",
    "        for i,no in enumerate(lista[node]):       \n",
    "            idx = no\n",
    "            node_to_list = [lista[node][i]]\n",
    "            lista[node][i] = 'x'\n",
    "            if no == 'x':\n",
    "                continue\n",
    "            if 'x' in lista[no]:\n",
    "                get_ancestrals(lista, idx, lista_nova)   \n",
    "            elif not lista[no]:\n",
    "                lista_nova.extend(node_to_list)\n",
    "                lista[no] = ['x']\n",
    "                continue\n",
    "            else:\n",
    "                lista_nova.extend(node_to_list)\n",
    "                get_ancestrals(lista, idx, lista_nova)             \n",
    "        else:\n",
    "            return get_ancestrals(lista, node, lista_nova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_aciclic_graph(grafo_param):\n",
    "    graph_mat = copy.deepcopy(grafo_param)\n",
    "    grafo_ac = np.zeros([len(graph_mat), len(graph_mat)], dtype=float)\n",
    "    ancestrals = [[] for el in np.arange(0, len(graph_mat))]\n",
    "    \n",
    "    max_val = max(graph_mat.flatten().tolist())\n",
    "    idx_max = np.argmax(graph_mat.flatten().tolist())  \n",
    "\n",
    "    while(max_val > 0):\n",
    "        idx_row = int(np.floor(idx_max)/len(graph_mat))\n",
    "        idx_col = idx_max - len(graph_mat)*idx_row\n",
    "\n",
    "        impossible_nodes = []\n",
    "        if ancestrals[idx_row]:\n",
    "            impossible_nodes = get_ancestrals(copy.deepcopy(ancestrals),idx_row, [])\n",
    "            if not idx_col in impossible_nodes:\n",
    "                grafo_ac[idx_row, idx_col] = graph_mat[idx_row, idx_col]\n",
    "                ancestrals[idx_col] += [idx_row] \n",
    "        else:\n",
    "            ancestrals[idx_col] += [idx_row]\n",
    "            grafo_ac[idx_row,idx_col] = max_val\n",
    "\n",
    "        graph_mat[idx_row, idx_col] = 0\n",
    "        max_val = max(graph_mat.flatten().tolist())\n",
    "        idx_max = np.argmax(graph_mat.flatten())\n",
    "    return grafo_ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lags_ances(mat, idx, soma, lista_lags, ref):\n",
    "    \n",
    "    if np.all(mat[:,idx] == np.zeros(len(mat))):\n",
    "        mat[idx] =  [-1 for peso in mat[idx]]\n",
    "        return 0\n",
    "\n",
    "    for i,dad_lag in enumerate(mat[:,idx]):\n",
    "        if dad_lag != 0:\n",
    "            if not np.all(mat[i] == [-1 for peso in mat[i]]):\n",
    "                soma += dad_lag\n",
    "                lista_lags.append((str(i), soma))\n",
    "                get_lags_ances(mat, i, soma, lista_lags, ref)\n",
    "                \n",
    "                soma = 0\n",
    "\n",
    "           \n",
    "    return lista_lags\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oDS2t1TEzrOX"
   },
   "outputs": [],
   "source": [
    "# dist6 = pd.read_csv(\"dist6_3horas_sig/alm_seq.csv\")\n",
    "# dist = dist6[['xmeas%02d_low' % x for x in [1,2,3,8,9,21]] + ['xmeas%02d_high' % x for x in [1,2,3,8,9,21]]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XMEAS01</th>\n",
       "      <th>XMEAS02</th>\n",
       "      <th>XMEAS03</th>\n",
       "      <th>XMEAS06</th>\n",
       "      <th>XMEAS07</th>\n",
       "      <th>XMEAS08</th>\n",
       "      <th>XMEAS09</th>\n",
       "      <th>XMEAS21</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOUT</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2019-12-10 16:54:17.616330147</td>\n",
       "      <td>0.271033</td>\n",
       "      <td>3649.739415</td>\n",
       "      <td>4451.320791</td>\n",
       "      <td>47.559754</td>\n",
       "      <td>2798.975799</td>\n",
       "      <td>64.995825</td>\n",
       "      <td>122.898796</td>\n",
       "      <td>102.480028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-12-10 16:54:53.616330147</td>\n",
       "      <td>0.270093</td>\n",
       "      <td>3663.351750</td>\n",
       "      <td>4428.605105</td>\n",
       "      <td>47.917222</td>\n",
       "      <td>2799.059838</td>\n",
       "      <td>65.254940</td>\n",
       "      <td>122.883398</td>\n",
       "      <td>102.484819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-12-10 16:55:29.616330147</td>\n",
       "      <td>0.271255</td>\n",
       "      <td>3656.090868</td>\n",
       "      <td>4429.093949</td>\n",
       "      <td>47.750928</td>\n",
       "      <td>2799.345791</td>\n",
       "      <td>64.930642</td>\n",
       "      <td>122.909663</td>\n",
       "      <td>102.499473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-12-10 16:56:05.616330147</td>\n",
       "      <td>0.269950</td>\n",
       "      <td>3664.897833</td>\n",
       "      <td>4439.129238</td>\n",
       "      <td>47.305023</td>\n",
       "      <td>2799.251300</td>\n",
       "      <td>65.188788</td>\n",
       "      <td>122.909316</td>\n",
       "      <td>102.465085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-12-10 16:56:41.616330147</td>\n",
       "      <td>0.270947</td>\n",
       "      <td>3616.540495</td>\n",
       "      <td>4446.078748</td>\n",
       "      <td>47.813862</td>\n",
       "      <td>2798.967112</td>\n",
       "      <td>65.686033</td>\n",
       "      <td>122.887484</td>\n",
       "      <td>102.463271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                XMEAS01      XMEAS02      XMEAS03    XMEAS06  \\\n",
       "TOUT                                                                           \n",
       "2019-12-10 16:54:17.616330147  0.271033  3649.739415  4451.320791  47.559754   \n",
       "2019-12-10 16:54:53.616330147  0.270093  3663.351750  4428.605105  47.917222   \n",
       "2019-12-10 16:55:29.616330147  0.271255  3656.090868  4429.093949  47.750928   \n",
       "2019-12-10 16:56:05.616330147  0.269950  3664.897833  4439.129238  47.305023   \n",
       "2019-12-10 16:56:41.616330147  0.270947  3616.540495  4446.078748  47.813862   \n",
       "\n",
       "                                   XMEAS07    XMEAS08     XMEAS09     XMEAS21  \n",
       "TOUT                                                                           \n",
       "2019-12-10 16:54:17.616330147  2798.975799  64.995825  122.898796  102.480028  \n",
       "2019-12-10 16:54:53.616330147  2799.059838  65.254940  122.883398  102.484819  \n",
       "2019-12-10 16:55:29.616330147  2799.345791  64.930642  122.909663  102.499473  \n",
       "2019-12-10 16:56:05.616330147  2799.251300  65.188788  122.909316  102.465085  \n",
       "2019-12-10 16:56:41.616330147  2798.967112  65.686033  122.887484  102.463271  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_path = 'proc_i3e.csv'\n",
    "proc_df = pd.read_csv(proc_path, index_col='TOUT', usecols=['TOUT']+[\"XMEAS%02d\" % x for x in  [1,2,3,6,7,8,9,21]])\n",
    "proc_df.index = pd.to_datetime(proc_df.index, unit='s')\n",
    "proc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_alarms = set_point.generate(dist8_proc_sv, thresh_high)\n",
    "low_alarms = set_point.generate(dist8_proc_sv, thresh_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying 5 samples mooving mean\n",
    "df_mean5 = apply_roll_mean(dist, 5)\n",
    "df_mean5.to_csv(\"resultados_defesa/alm_seq_m5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_roc = 0.01816308533330481\n",
    "t_roc2 = 0.055674922579944816\n",
    "df_ltd = generate_df_valid_corrs(df_te, t_roc)\n",
    "df_ltd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lags_ances_df(mat,idx, soma, dict_lags, lista, dict_caminhos):\n",
    "    lista.append(idx)\n",
    "    if np.all(mat[idx] == np.zeros(len(mat))):\n",
    "        return [dict_lags,dict_caminhos]\n",
    "    for i,dad_lag in enumerate(mat[idx]):\n",
    "        if dad_lag > 0:\n",
    "          \n",
    "            soma += dad_lag\n",
    "            try:\n",
    "                dict_lags[mat.columns[i]].append(soma)\n",
    "                dict_caminhos[mat.columns[i]].append(lista)\n",
    "            except:\n",
    "                dict_lags[mat.columns[i]] = [soma]\n",
    "                dict_caminhos[mat.columns[i]]= [lista]\n",
    "        \n",
    "            get_lags_ances_df(mat, mat.columns[i], soma, dict_lags, lista[:], dict_caminhos)\n",
    "            soma -= dad_lag\n",
    "            \n",
    "    return [dict_lags, dict_caminhos] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building DF from te matrix\n",
    "t = np.mean(te_matrix[0]) + 3*np.std(te_matrix[0])\n",
    "df_te = pd.DataFrame(te_matrix[0], columns = dist.columns, index= dist.columns)\n",
    "df_te_lag = pd.DataFrame(te_matrix[1], columns = dist.columns, index= dist.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_shifts(nodes, mat):\n",
    "    dic = {}\n",
    "    for node in nodes:\n",
    "        mat_cp = mat.copy()\n",
    "#         if not np.all(mat_cp[node] == np.zeros(len(mat_cp))):\n",
    "        dic[node] = get_lags_ances_df(mat_cp, node, 0, {}, [],{})[0]\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen_tree_from_lags(dici):\n",
    "    tree_k2 = {}\n",
    "    for key_son, value in dici.items():    \n",
    "        if value:\n",
    "            for key_dad, value_dad in value.items():\n",
    "                for i, value in enumerate(value_dad):\n",
    "                    try:\n",
    "                        tree_k2[key_son].append(key_dad+\"-\"+str(i)+\"_\"+str(int(value)))\n",
    "                    except:\n",
    "                         tree_k2[key_son] = [key_dad+\"-\"+str(i)+\"_\"+str(int(value))]\n",
    "                            \n",
    "                    tree_k2[key_dad+\"-\"+str(i)+\"_\"+str(int(value))] = []\n",
    "        else:\n",
    "            tree_k2[key_son] = []\n",
    "    return tree_k2  \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_df_iteration(df, node, dict_lag):\n",
    "    df_gen = df.copy()\n",
    "    if dict_lag[node]:\n",
    "        for key_dad, values_dad in dict_lag[node].items():\n",
    "            for i, val in enumerate(dict_lag[node][key_dad]): \n",
    "                df_gen[key_dad+\"-\"+str(i)+\"_\"+str(int(val))] = shift(df_gen[key_dad], int(val), order=0, mode='constant', cval=np.NaN)\n",
    "    df_gen.dropna(inplace=True)\n",
    "    return df_gen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lags_final  = df_te_lag[df_graph_ltd_ac > 0].fillna(0)\n",
    "df_lags_final.to_csv('resultados_defesa/df_lags_ltd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gen_df_iteration(df_mean5, 'xmeas01_high', dict_all_lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_all_lags = get_all_shifts(df_lags_final.columns, df_lags_final.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph(df_graph_ltd_ac, df_lags_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##transformar em função\n",
    "\n",
    "lista_9 = get_lags_ances_df(df_lags_final, 'xmeas01_high',0, {}, [], {})[1]\n",
    "\n",
    "df_clean = pd.DataFrame(data=np.zeros([len(df_lags_final.columns),len(df_lags_final.columns)], dtype=float), columns= df_lags_final.columns, index= df_lags_final.columns) \n",
    "\n",
    "\n",
    "count = 0\n",
    "node_ref = 'xmeas09_high'\n",
    "idx_ref = 0\n",
    "node_son = 'xmeas01_high'\n",
    "\n",
    "path_list = lista_9[node_ref][idx_ref][::-1]\n",
    "while count < len(lista_9[node_ref][idx_ref][::-1]) -1:\n",
    "\n",
    "    if len(lista_9[node_ref][idx_ref][::-1]) == 1:\n",
    "        df_clean.at[node_ref,node_son] = 1\n",
    "    else:\n",
    "        df_clean.at[path_list[count], path_list[count+1]] = 1\n",
    "    count +=1\n",
    "     \n",
    "df_clean.at[node_ref, path_list[0]] = 1\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "TransEntropy.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
